{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0.1\n",
    "## Introduction to EM data, neuron segmentation and gunpowder\n",
    "### A simple gunpowder example pipeline for loading and manipulating data\n",
    "\n",
    "Become familiar with gunpowder. Read and try to understand the following code as well as the general principle behind gunpowder. Read the introductory example in the gunpowder documentation http://funkey.science/gunpowder and gunpowder tutorial http://funkey.science/gunpowder/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from gunpowder import *\n",
    "from gunpowder.tensorflow import *\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# A simple gunpowder pipeline for loading and manipulating data:\n",
    "data_dir = '../../jan/segmentation/data'\n",
    "\n",
    "# Define gunpowder variables of interest:\n",
    "raw = ArrayKey('RAW') # Raw EM data\n",
    "labels = ArrayKey('GT_LABELS') # ground truth neuron segmentation \n",
    "affinities = ArrayKey('GT_AFFINITIES') # affinities\n",
    "\n",
    "# Voxel size is the physical size of one voxel (=3D pixel) in nm.\n",
    "voxel_size = Coordinate((40, 4, 4))\n",
    "batch_size = Coordinate((50,1000,1000)) * voxel_size\n",
    "\n",
    "# Request all the data you need for training:\n",
    "request = BatchRequest()\n",
    "request.add(raw, batch_size)\n",
    "request.add(labels, batch_size)\n",
    "request.add(affinities, batch_size)\n",
    "\n",
    "selec_roi = Roi(offset=(3000,5000,5100), shape=batch_size)\n",
    "request[raw].roi = selec_roi\n",
    "request[labels].roi = selec_roi\n",
    "request[affinities].roi = selec_roi\n",
    "\n",
    "# Request a snapshot s.t. you are able to visualize the data in your pipeline.\n",
    "snapshot_request = BatchRequest({\n",
    "    raw: request[raw],\n",
    "    labels: request[labels],\n",
    "    affinities: request[affinities]\n",
    "})\n",
    "\n",
    "# Note that the data only provides raw and neuron_ids which is the neuron segmentation.\n",
    "# However, we need affinities which we can generate from neuron_ids by using gunpowder (see below):\n",
    "data_sources = tuple(\n",
    "    N5Source(\n",
    "        os.path.join(data_dir, sample + '.n5'),\n",
    "        datasets = {\n",
    "            raw: 'volumes/raw',\n",
    "            labels: 'volumes/labels/neuron_ids',\n",
    "        },\n",
    "        array_specs = {\n",
    "            raw: ArraySpec(interpolatable=True),\n",
    "            labels: ArraySpec(interpolatable=False)\n",
    "        }\n",
    "    ) +\n",
    "    Normalize(raw)\n",
    "    for sample in [\"sample_C\"]\n",
    "    )\n",
    "\n",
    "# Define a neighborhood for affinities:\n",
    "neighborhood = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Build the actual data-pipeline:\n",
    "\n",
    "def basic_pipeline():\n",
    "    pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        AddAffinities(neighborhood,\n",
    "                     labels=labels,\n",
    "                     affinities=affinities) +\n",
    "        Snapshot(dataset_names={raw: 'volumes/raw',\n",
    "                  labels: 'volumes/labels/neuron_ids',\n",
    "                  affinities: 'volumes/affinities'},\n",
    "                  output_filename=\"snapshot_basic.hdf\"))\n",
    "    return pipeline\n",
    "\n",
    "def simple_augment_pipeline():\n",
    "    pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        SimpleAugment(transpose_only=[1, 2]) +\n",
    "        AddAffinities(neighborhood,\n",
    "                     labels=labels,\n",
    "                     affinities=affinities) +\n",
    "        Snapshot(dataset_names={raw: 'volumes/raw',\n",
    "                  labels: 'volumes/labels/neuron_ids',\n",
    "                  affinities: 'volumes/affinities'},\n",
    "                  output_filename=\"snapshot_simple.hdf\"))\n",
    "    return pipeline\n",
    "\n",
    "def intensity_augment_pipeline():\n",
    "    pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        IntensityAugment(raw, 0.9, 1.1, -0.1, 0.1, z_section_wise=True) +    \n",
    "        AddAffinities(neighborhood,\n",
    "                     labels=labels,\n",
    "                     affinities=affinities) +\n",
    "        Snapshot(dataset_names={raw: 'volumes/raw',\n",
    "                  labels: 'volumes/labels/neuron_ids',\n",
    "                  affinities: 'volumes/affinities'},\n",
    "                  output_filename=\"snapshot_intensity.hdf\"))\n",
    "    return pipeline\n",
    "\n",
    "def elastic_augment_pipeline():\n",
    "    pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        ElasticAugment(\n",
    "            control_point_spacing=[4,40,40],\n",
    "            jitter_sigma=[0,2,2],\n",
    "            rotation_interval=[0,math.pi/2.0],\n",
    "            prob_slip=0.05,\n",
    "            prob_shift=0.05,\n",
    "            max_misalign=10,\n",
    "            subsample=8) +\n",
    "        AddAffinities(neighborhood,\n",
    "                     labels=labels,\n",
    "                     affinities=affinities) +\n",
    "        Snapshot(dataset_names={raw: 'volumes/raw',\n",
    "                  labels: 'volumes/labels/neuron_ids',\n",
    "                  affinities: 'volumes/affinities'},\n",
    "                  output_filename=\"snapshot_elastic.hdf\"))\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "#EXERCISE: IMPLEMENT THE KING OF THE NORTH PIPELINE - CHAINING ALL AUGMENTATIONS TOGETHER!\n",
    "\"\"\"\n",
    "def king_of_the_north():\n",
    "    pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        \n",
    "        IMPLEMENT ALL AUGMENTATIONS \n",
    "        TOGETHER IN ONE PIPELINE HERE!\n",
    "        Use the prior functions for reference.\n",
    "        You can also play around with the parameters\n",
    "        and do crazy stuff.\n",
    "        \n",
    "        AddAffinities(neighborhood,\n",
    "                     labels=labels,\n",
    "                     affinities=affinities) +\n",
    "        Snapshot(dataset_names={raw: 'volumes/raw',\n",
    "                  labels: 'volumes/labels/neuron_ids',\n",
    "                  affinities: 'volumes/affinities'},\n",
    "                  output_filename=\"snapshot_king_of_the_north.hdf\"))\n",
    "    \n",
    "    return pipeline\n",
    "\"\"\"\n",
    "\n",
    "pipeline_setups={\"basic\": basic_pipeline,\n",
    "                 \"simple\": simple_augment_pipeline,\n",
    "                 \"intensity\": intensity_augment_pipeline,\n",
    "                 \"elastic\": elastic_augment_pipeline}\n",
    "\n",
    "try:\n",
    "    pipeline_setups.update({\"king_of_the_north\": king_of_the_north})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0.2\n",
    "## Choose a pipeline and understand how different augmentation types influence the output.\n",
    "\n",
    "### You can choose between:\n",
    "1. basic (No augmentations)\n",
    "2. simple\n",
    "3. intensity \n",
    "4. elastic\n",
    "5. (*If you implemented it: king_of_the_north)\n",
    "\n",
    "Try to find out what each of these are actually doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a pipeline, run it and observe the differences in neuroglancer.\n",
    "pipeline_name = \"basic\"\n",
    "\n",
    "if not os.path.exists(\"./snapshots\"):\n",
    "    os.makedirs(\"./snapshots\")\n",
    "pipeline_setup = pipeline_setups[pipeline_name]\n",
    "\n",
    "with build(pipeline_setup()) as b:\n",
    "    b.request_batch(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data using neuroglancer\n",
    "\n",
    "The prior cell generated a file in your working directory containg the raw EM data, neuron segmentation and affinities. The following script lets you view the data you just generated and will change depending on which augmentation pipeline you choose. Run both cells below and click on the resulting link. You can enable and disable layers by clicking on them. Explore the data. What do the different colors of the affinities mean? How does it relate to the segmentation? How is augmentation affecting the data?\n",
    "\n",
    "If you double click on a particular segment neuroglancer allows you to view the 3D mesh of the object.\n",
    "\n",
    "### Dataset:\n",
    "The data you are looking at are a tiny subset of the **whole** adult Drosophila brain, imaged via serial section transmission electron microscopy (SSTEM) ([Zheng et al. 2018](https://www.sciencedirect.com/science/article/pii/S0092867418307876)). If you are curious and want to get a sense of the scale, [here](https://fafb.catmaid.virtualflybrain.org/?pid=1&zp=127040&yp=253133.36932477387&xp=585045.0300033365&tool=navigator&sid0=1&s0=7.400000000000001) you can browse the entire dataset. Zooming in and out is a lot of fun, don't get lost.\n",
    "\n",
    "The particular cutout you are looking at here, is itself a small cutout of the [CREMI](https://cremi.org/) challenge volumes: a neuron and synapse segmentation challenge that provides manually acquired ground truth and provides a way to quantitatively compare competing algorithmic approaches.\n",
    "\n",
    "##### REPLACE THE IP BELOW WITH YOURS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroglancer\n",
    "import funlib.show.neuroglancer as funlibng\n",
    "import daisy\n",
    "import numpy as np\n",
    "\n",
    "# !!! IMPORTANT: Replace my_ip with your public paperspace ip as shown in your browser !!!\n",
    "\n",
    "def view_snapshot(pipeline_name, my_ip=\"184.105.98.58\", snapshot_file=\"./snapshots/snapshot\"):\n",
    "    neuroglancer.set_server_bind_address('0.0.0.0', 8889)\n",
    "    snapshot_file = snapshot_file + \"_\" + pipeline_name + \".hdf\"\n",
    "    \n",
    "    affs_ds = daisy.open_ds(snapshot_file, 'volumes/affinities')\n",
    "    affs_ds.data = np.array(affs_ds.data, dtype=np.float32)\n",
    "    labels_ds = daisy.open_ds(snapshot_file, 'volumes/labels/neuron_ids')\n",
    "    raw_ds = daisy.open_ds(snapshot_file, 'volumes/raw')\n",
    "\n",
    "    neuroglancer.set_server_bind_address('0.0.0.0')\n",
    "    viewer = neuroglancer.Viewer()\n",
    "    with viewer.txn() as s:\n",
    "        funlibng.add_layer(s, raw_ds, 'raw')\n",
    "        funlibng.add_layer(s, labels_ds, 'labels')\n",
    "        funlibng.add_layer(s, affs_ds, 'affinities', shader='rgb')\n",
    "\n",
    "    print(viewer.__str__().replace(\"localhost\", my_ip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://184.105.98.58:41201/v/a608079c61971aa339a05cf0bc8fb699f5c055d6/\n"
     ]
    }
   ],
   "source": [
    "view_snapshot(pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## Using gunpowder with tensorflow for training a 3D-UNet for affinity prediction\n",
    "#### mknet.py\n",
    "\n",
    "In this exercise we ask you to pick a network of your choosing to create a computation graph for your neural network. Follow the instructions in the code and make use of help and documentations.\n",
    "\n",
    "As usual if you are not sure about what a function does or what its argument is navigate to the function and press ```shift + tab``` to display arguments and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5655611066949055660\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7697914266\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 8735509405345732759\n",
      "physical_device_desc: \"device: 0, name: Quadro P4000, pci bus id: 0000:00:05.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output above doesn't mention the word GPU scream HELP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funlib.learn.tensorflow import models\n",
    "import malis\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "\n",
    "def create_network(name, input_shape, num_fmaps, fmap_inc_factors, downsample_factors):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.variable_scope('setup0'):\n",
    "\n",
    "        raw = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        raw_batched = tf.reshape(raw, (1, 1) + input_shape)\n",
    "\n",
    "        unet, _, _ = models.unet(\n",
    "                raw_batched,\n",
    "                num_fmaps,\n",
    "                fmap_inc_factors,\n",
    "                downsample_factors)\n",
    "\n",
    "        affs_batched, _ = models.conv_pass(\n",
    "            unet,\n",
    "            kernel_sizes=[1],\n",
    "            num_fmaps=3,\n",
    "            activation='sigmoid',\n",
    "            name='affs')\n",
    "\n",
    "        output_shape_batched = affs_batched.get_shape().as_list()\n",
    "        output_shape = output_shape_batched[1:] # strip the batch dimension\n",
    "\n",
    "        affs = tf.reshape(affs_batched, output_shape)\n",
    "\n",
    "        gt_affs = tf.placeholder(tf.float32, shape=output_shape)\n",
    "        affs_loss_weights = tf.placeholder(tf.float32, shape=output_shape)\n",
    "\n",
    "        loss = tf.losses.mean_squared_error(\n",
    "            gt_affs,\n",
    "            affs,\n",
    "            affs_loss_weights)\n",
    "\n",
    "        summary = tf.summary.scalar('setup0', loss)\n",
    "\n",
    "        opt = tf.train.AdamOptimizer(\n",
    "            learning_rate=0.5e-4,\n",
    "            beta1=0.95,\n",
    "            beta2=0.999,\n",
    "            epsilon=1e-8)\n",
    "        optimizer = opt.minimize(loss)\n",
    "\n",
    "        output_shape = output_shape[1:]\n",
    "        print(\"input shape : %s\"%(input_shape,))\n",
    "        print(\"output shape: %s\"%(output_shape,))\n",
    "\n",
    "        tf.train.export_meta_graph(filename=name + '.meta')\n",
    "\n",
    "        config = {\n",
    "            'raw': raw.name,\n",
    "            'affs': affs.name,\n",
    "            'gt_affs': gt_affs.name,\n",
    "            'affs_loss_weights': affs_loss_weights.name,\n",
    "            'loss': loss.name,\n",
    "            'optimizer': optimizer.name,\n",
    "            'input_shape': input_shape,\n",
    "            'output_shape': output_shape,\n",
    "            'summary': summary.name\n",
    "        }\n",
    "\n",
    "        config['outputs'] = {'affs': {\"out_dims\": 3, \"out_dtype\": \"uint8\"}}\n",
    "\n",
    "        with open(name + '.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "        \n",
    "        if name==\"arya\":\n",
    "            print(\"\\nVALAR MORGHULIS\")\n",
    "        if name==\"jon\":\n",
    "            print(\"\\nFOR THE NORTH\")\n",
    "        if name==\"daenerys\":\n",
    "            print(\"\\nDRACARYS\")\n",
    "        if name==\"cersei\":\n",
    "            print(\"\\nJAIME!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you find a selection of your favorite 3D-UNets in Westeros. Make use of the following documentation to decide which of these networks is to your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.unet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arya_stark = {\"name\": \"arya\", \n",
    "        \"input_shape\": (84, 268, 268),\n",
    "        \"num_fmaps\": 12,\n",
    "        \"fmap_inc_factors\": 5,\n",
    "        \"downsample_factors\": [[2,3,3],[4,12,12]]}\n",
    "\n",
    "jon_snow = {\"name\": \"jon\", \n",
    "        \"input_shape\": (84, 268, 268),\n",
    "        \"num_fmaps\": 12,\n",
    "        \"fmap_inc_factors\": 5,\n",
    "        \"downsample_factors\": [[1,3,3],[1,3,3],[3,3,3]]}\n",
    "\n",
    "daenerys_stormborn = {\"name\": \"daenerys\", \n",
    "                      \"input_shape\": (84, 268, 268),\n",
    "                      \"num_fmaps\": 12,\n",
    "                      \"fmap_inc_factors\": 2,\n",
    "                      \"downsample_factors\": [[1,3,3],[1,3,3],[3,1,1],[2,2,2]]}\n",
    "\n",
    "cersei_lennister = {\"name\": \"cersei\", \n",
    "                    \"input_shape\": (84, 268, 268),\n",
    "                    \"num_fmaps\": 24,\n",
    "                    \"fmap_inc_factors\": 1,\n",
    "                    \"downsample_factors\": [[2,3,3],[1,2,2],[1,1,1],[1,1,1]]}\n",
    "\n",
    "networks = {\"arya\": arya_stark, \n",
    "            \"jon\": jon_snow, \n",
    "            \"daenerys\": daenerys_stormborn, \n",
    "            \"cersei\": cersei_lennister}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick your network\n",
    "Choose between Arya, Jon, Daenerys and Cersei described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating U-Net layer 0\n",
      "f_in: (1, 1, 84, 268, 268)\n",
      "number of variables added: 16248, new total: 16248\n",
      "    Creating U-Net layer 1\n",
      "    f_in: (1, 24, 40, 88, 88)\n",
      "    number of variables added: 31152, new total: 47400\n",
      "        Creating U-Net layer 2\n",
      "        f_in: (1, 24, 36, 42, 42)\n",
      "        number of variables added: 31152, new total: 78552\n",
      "            Creating U-Net layer 3\n",
      "            f_in: (1, 24, 32, 38, 38)\n",
      "            number of variables added: 31152, new total: 109704\n",
      "                Creating U-Net layer 4\n",
      "                f_in: (1, 24, 28, 34, 34)\n",
      "                bottom layer\n",
      "                f_out: (1, 24, 24, 30, 30)\n",
      "                number of variables added: 31152, new total: 140856\n",
      "            g_out: (1, 24, 24, 30, 30)\n",
      "            g_out_upsampled: (1, 24, 24, 30, 30)\n",
      "            f_left_cropped: (1, 24, 24, 30, 30)\n",
      "            f_right: (1, 48, 24, 30, 30)\n",
      "            f_out: (1, 24, 20, 26, 26)\n",
      "            number of variables added: 47304, new total: 188160\n",
      "        g_out: (1, 24, 20, 26, 26)\n",
      "        g_out_upsampled: (1, 24, 20, 26, 26)\n",
      "        f_left_cropped: (1, 24, 20, 26, 26)\n",
      "        f_right: (1, 48, 20, 26, 26)\n",
      "        f_out: (1, 24, 16, 22, 22)\n",
      "        number of variables added: 47304, new total: 235464\n",
      "    g_out: (1, 24, 16, 22, 22)\n",
      "    g_out_upsampled: (1, 24, 16, 44, 44)\n",
      "    f_left_cropped: (1, 24, 16, 44, 44)\n",
      "    f_right: (1, 48, 16, 44, 44)\n",
      "    f_out: (1, 24, 12, 40, 40)\n",
      "    number of variables added: 49032, new total: 284496\n",
      "g_out: (1, 24, 12, 40, 40)\n",
      "g_out_upsampled: (1, 24, 24, 120, 120)\n",
      "f_left_cropped: (1, 24, 24, 120, 120)\n",
      "f_right: (1, 48, 24, 120, 120)\n",
      "f_out: (1, 24, 20, 116, 116)\n",
      "number of variables added: 57096, new total: 341592\n",
      "input shape : (84, 268, 268)\n",
      "output shape: [20, 116, 116]\n",
      "\n",
      "JAIME!\n"
     ]
    }
   ],
   "source": [
    "network = \"cersei\"\n",
    "create_network(**networks[network])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "## A gunpowder training pipeline\n",
    "\n",
    "In this exercise we ask you to use gunpowder in combination with tensorflow to train your chosen network. You should start the training today but it will need to run the entire night so we can use the results tomorrow. Do not stop the training when you leave tonight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train cersei\n",
      "CONTEXT:  (400, 232, 232)\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-1c5dbf659ca8>\", line 166, in <module>\n",
      "    train_until(iteration)\n",
      "  File \"<ipython-input-19-1c5dbf659ca8>\", line 160, in train_until\n",
      "    b.request_batch(request)\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/batch_provider.py\", line 146, in request_batch\n",
      "    batch = self.provide(copy.deepcopy(request))\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/batch_provider_tree.py\", line 45, in provide\n",
      "    return self.output.request_batch(request)\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/batch_provider.py\", line 146, in request_batch\n",
      "    batch = self.provide(copy.deepcopy(request))\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/batch_filter.py\", line 128, in provide\n",
      "    batch = self.get_upstream_provider().request_batch(upstream_request)\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/batch_provider.py\", line 146, in request_batch\n",
      "    batch = self.provide(copy.deepcopy(request))\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/batch_filter.py\", line 128, in provide\n",
      "    batch = self.get_upstream_provider().request_batch(upstream_request)\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/batch_provider.py\", line 146, in request_batch\n",
      "    batch = self.provide(copy.deepcopy(request))\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/batch_filter.py\", line 128, in provide\n",
      "    batch = self.get_upstream_provider().request_batch(upstream_request)\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/batch_provider.py\", line 146, in request_batch\n",
      "    batch = self.provide(copy.deepcopy(request))\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/batch_filter.py\", line 128, in provide\n",
      "    batch = self.get_upstream_provider().request_batch(upstream_request)\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/batch_provider.py\", line 146, in request_batch\n",
      "    batch = self.provide(copy.deepcopy(request))\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/nodes/precache.py\", line 65, in provide\n",
      "    batch = self.workers.get()\n",
      "  File \"/home/paperspace/Code/wh2019_segmentation/src/gunpowder/gunpowder/producer_pool.py\", line 59, in get\n",
      "    item = self.__result_queue.get(timeout=timeout)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/inspect.py\", line 1454, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/inspect.py\", line 666, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/inspect.py\", line 709, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/inspect.py\", line 679, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/posixpath.py\", line 376, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/posixpath.py\", line 363, in normpath\n",
      "    path = sep*initial_slashes + path\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "from gunpowder import *\n",
    "from gunpowder.tensorflow import *\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "data_dir = '../../jan/segmentation/data'\n",
    "\n",
    "samples = [\n",
    "    'sample_A',\n",
    "    'sample_B',\n",
    "    'sample_C'\n",
    "]\n",
    "\n",
    "neighborhood = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]\n",
    "\n",
    "def train_until(max_iteration):\n",
    "    print(\"Train \" + network)\n",
    "    if tf.train.latest_checkpoint('.'):\n",
    "        trained_until = int(tf.train.latest_checkpoint('.').split('_')[-1])\n",
    "    else:\n",
    "        trained_until = 0\n",
    "    if trained_until >= max_iteration:\n",
    "        return\n",
    "\n",
    "    with open('{}.json'.format(network), 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    raw = ArrayKey('RAW')\n",
    "    labels = ArrayKey('GT_LABELS')\n",
    "    labels_mask = ArrayKey('GT_LABELS_MASK')\n",
    "    affs = ArrayKey('PREDICTED_AFFS')\n",
    "    gt = ArrayKey('GT_AFFINITIES')\n",
    "    gt_mask = ArrayKey('GT_AFFINITIES_MASK')\n",
    "    gt_scale = ArrayKey('GT_AFFINITIES_SCALE')\n",
    "    affs_gradient = ArrayKey('AFFS_GRADIENT')\n",
    "\n",
    "    voxel_size = Coordinate((40, 4, 4))\n",
    "    input_size = Coordinate(config['input_shape'])*voxel_size\n",
    "    output_size = Coordinate(config['output_shape'])*voxel_size\n",
    "    context = output_size/2\n",
    "    print('CONTEXT: ', context)\n",
    "\n",
    "    request = BatchRequest()\n",
    "    request.add(raw, input_size)\n",
    "    request.add(labels, output_size)\n",
    "    request.add(labels_mask, output_size)\n",
    "    request.add(gt, output_size)\n",
    "    request.add(gt_mask, output_size)\n",
    "    request.add(gt_scale, output_size)\n",
    "\n",
    "    snapshot_request = BatchRequest({\n",
    "        affs: request[gt],\n",
    "        affs_gradient: request[gt]\n",
    "    })\n",
    "\n",
    "    data_sources = tuple(\n",
    "        N5Source(\n",
    "            os.path.join(data_dir, sample + '.n5'),\n",
    "            datasets = {\n",
    "                raw: 'volumes/raw',\n",
    "                labels: 'volumes/labels/neuron_ids',\n",
    "                labels_mask: 'volumes/labels/mask',\n",
    "            },\n",
    "            array_specs = {\n",
    "                raw: ArraySpec(interpolatable=True),\n",
    "                labels: ArraySpec(interpolatable=False),\n",
    "                labels_mask: ArraySpec(interpolatable=False)\n",
    "            }\n",
    "        ) +\n",
    "        Normalize(raw) +\n",
    "        Pad(labels, context) +\n",
    "        Pad(labels_mask, context) +\n",
    "        RandomLocation() +\n",
    "        Reject(mask=labels_mask)\n",
    "        for sample in samples\n",
    "    )\n",
    "\n",
    "\n",
    "    train_pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        ElasticAugment(\n",
    "            control_point_spacing=[4,40,40],\n",
    "            jitter_sigma=[0,2,2],\n",
    "            rotation_interval=[0,math.pi/2.0],\n",
    "            prob_slip=0.05,\n",
    "            prob_shift=0.05,\n",
    "            max_misalign=10,\n",
    "            subsample=8) +\n",
    "        SimpleAugment(transpose_only=[1, 2]) +\n",
    "        IntensityAugment(raw, 0.9, 1.1, -0.1, 0.1, z_section_wise=True) +\n",
    "        GrowBoundary(labels, labels_mask, steps=1, only_xy=True) +\n",
    "        AddAffinities(\n",
    "            neighborhood,\n",
    "            labels=labels,\n",
    "            affinities=gt,\n",
    "            labels_mask=labels_mask,\n",
    "            affinities_mask=gt_mask) +\n",
    "        BalanceLabels(\n",
    "            gt,\n",
    "            gt_scale,\n",
    "            gt_mask) +\n",
    "        DefectAugment(\n",
    "            raw,\n",
    "            prob_missing=0.03,\n",
    "            prob_low_contrast=0.01,\n",
    "            contrast_scale=0.5,\n",
    "            axis=0) +\n",
    "        IntensityScaleShift(raw, 2,-1) +\n",
    "        PreCache(cache_size=40,\n",
    "                 num_workers=10) +\n",
    "        Train(\n",
    "            network,\n",
    "            optimizer=config['optimizer'],\n",
    "            loss=config['loss'],\n",
    "            inputs={\n",
    "                config['raw']: raw,\n",
    "                config['gt_affs']: gt,\n",
    "                config['affs_loss_weights']: gt_scale,\n",
    "            },\n",
    "            outputs={\n",
    "                config['affs']: affs\n",
    "            },\n",
    "            gradients={\n",
    "                config['affs']: affs_gradient\n",
    "            },\n",
    "            summary=config['summary'],\n",
    "            log_dir='log',\n",
    "            save_every=20000) +\n",
    "        IntensityScaleShift(raw, 0.5, 0.5) +\n",
    "        Snapshot({\n",
    "                raw: 'volumes/raw',\n",
    "                labels: 'volumes/labels/neuron_ids',\n",
    "                gt: 'volumes/gt_affinities',\n",
    "                affs: 'volumes/pred_affinities',\n",
    "                gt_mask: 'volumes/labels/gt_mask',\n",
    "                labels_mask: 'volumes/labels/mask',\n",
    "                affs_gradient: 'volumes/affs_gradient'\n",
    "            },\n",
    "            dataset_dtypes={\n",
    "                labels: np.uint64\n",
    "            },\n",
    "            every=10000,\n",
    "            output_filename='batch_{iteration}.hdf',\n",
    "            additional_request=snapshot_request) +\n",
    "        PrintProfilingStats(every=10)\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    with build(train_pipeline) as b:\n",
    "        for i in range(max_iteration - trained_until):\n",
    "            b.request_batch(request)\n",
    "    print(\"Training finished\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    iteration = 500000\n",
    "    train_until(iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "## Monitor the training progress\n",
    "\n",
    "Visualize the generated training snapshots with neuroglancer and observe loss curves using tensorboard.\n",
    "\n",
    "\n",
    "#### Snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroglancer\n",
    "import funlib.show.neuroglancer as funlibng\n",
    "import daisy\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "data_file = ...\n",
    "\"\"\"\n",
    "\n",
    "gt_affs_ds = daisy.open_ds(data_file, 'volumes/gt_affinities')\n",
    "gt_affs_ds.data = np.array(gt_affs_ds.data, dtype=np.float32)\n",
    "\n",
    "pred_affs_ds = daisy.open_ds(data_file, 'volumes/pred_affinities')\n",
    "pred_affs_ds.data = np.array(pred_affs_ds.data, dtype=np.float32)\n",
    "\n",
    "gradients_ds = daisy.open_ds(data_file, 'volumes/affs_gradient')\n",
    "\n",
    "labels_ds = daisy.open_ds(data_file, 'volumes/labels/neuron_ids')\n",
    "raw_ds = daisy.open_ds(data_file, 'volumes/raw')\n",
    "\n",
    "# Replace my_ip with your public paperspace ip as shown in your browser\n",
    "my_ip = \"172.83.14.204\"\n",
    "neuroglancer.set_server_bind_address('0.0.0.0', 8889)\n",
    "\n",
    "viewer = neuroglancer.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    funlibng.add_layer(s, raw_ds, 'raw')\n",
    "    funlibng.add_layer(s, labels_ds, 'labels')\n",
    "    funlibng.add_layer(s, gt_affs_ds, 'gt_affinities', shader='rgb')\n",
    "    funlibng.add_layer(s, pred_affs_ds, 'pred_affinities', shader='rgb')\n",
    "    funlibng.add_layer(s, gradients_ds, 'gradients')\n",
    "\n",
    "print(viewer.__str__().replace(\"localhost\", my_ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss\n",
    "To visualize your loss using tensorboard open a terminal and execute: \n",
    "```tensorboard --logdir=path/to/log-directory```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:segmentation]",
   "language": "python",
   "name": "conda-env-segmentation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
