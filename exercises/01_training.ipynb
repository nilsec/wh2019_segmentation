{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0.1\n",
    "## Introduction to EM data, neuron segmentation and gunpowder\n",
    "### A simple gunpowder example pipeline for loading and manipulating data\n",
    "\n",
    "Become familiar with gunpowder. Read and try to understand the following code as well as the general principle behind gunpowder. Read the introductory example in the gunpowder documentation: https://github.com/funkey/gunpowder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from gunpowder import *\n",
    "from gunpowder.tensorflow import *\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# A simple gunpowder pipeline for loading and manipulating data:\n",
    "data_dir = '../../jan/segmentation/data'\n",
    "\n",
    "samples = [\n",
    "    'sample_A',\n",
    "    'sample_B',\n",
    "    'sample_C'\n",
    "]\n",
    "\n",
    "\n",
    "# Define gunpowder variables of interest:\n",
    "raw = ArrayKey('RAW') # Raw EM data\n",
    "labels = ArrayKey('GT_LABELS') # ground truth neuron segmentation \n",
    "affinities = ArrayKey('GT_AFFINITIES') # affinities\n",
    "\n",
    "# Voxel size is the physical size of one voxel (=3D pixel) in nm.\n",
    "voxel_size = Coordinate((40, 4, 4))\n",
    "batch_size = Coordinate((30,1000,1000)) * voxel_size\n",
    "\n",
    "# Request all the data you need for training:\n",
    "request = BatchRequest()\n",
    "request.add(raw, batch_size)\n",
    "request.add(labels, batch_size)\n",
    "request.add(affinities, batch_size)\n",
    "\n",
    "# Request a snapshot s.t. you are able to visualize the data in your pipeline.\n",
    "snapshot_request = BatchRequest({\n",
    "    raw: request[raw],\n",
    "    labels: request[labels],\n",
    "    affinities: request[affinities]\n",
    "})\n",
    "\n",
    "# Note that the data only provides raw and neuron_ids which is the neuron segmentation.\n",
    "# However, we need affinities which we can generate from neuron_ids by using gunpowder (see below):\n",
    "data_sources = tuple(\n",
    "    N5Source(\n",
    "        os.path.join(data_dir, sample + '.n5'),\n",
    "        datasets = {\n",
    "            raw: 'volumes/raw',\n",
    "            labels: 'volumes/labels/neuron_ids',\n",
    "        },\n",
    "        array_specs = {\n",
    "            raw: ArraySpec(interpolatable=True),\n",
    "            labels: ArraySpec(interpolatable=False)\n",
    "        }\n",
    "    ) +\n",
    "    Normalize(raw) + \n",
    "    #Pad(labels, None) +\n",
    "    RandomLocation()\n",
    "    for sample in samples\n",
    "    )\n",
    "\n",
    "\n",
    "# Define a neighborhood for affinities:\n",
    "neighborhood = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]\n",
    "\n",
    "pipeline = (\n",
    "    data_sources +\n",
    "    RandomProvider() +\n",
    "    AddAffinities(neighborhood,\n",
    "                 labels=labels,\n",
    "                 affinities=affinities) +\n",
    "    Snapshot({raw: 'volumes/raw',\n",
    "              labels: 'volumes/labels/neuron_ids',\n",
    "              affinities: 'volumes/affinities'}))\n",
    "    \n",
    "    \n",
    "with build(pipeline) as b:\n",
    "    b.request_batch(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0.2 \n",
    "## Visualize data using neuroglancer\n",
    "\n",
    "Exercise 0.1 generated a file in your working directory containg the raw EM data, neuron segmentation and affinities. The following script lets you view the data. Run both cells below and click on the resulting link. You can enable and disable layers by clicking on them. Explore the data. What do the different colors of the affinities mean? How does it relate to the segmentation?\n",
    "\n",
    "If you double click on a particular segment neuroglancer allows you to view the 3D mesh of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://172.83.14.204:42551/v/cdffd852c880fef9568ebc2a30e1e67ca28845b1/\n"
     ]
    }
   ],
   "source": [
    "import neuroglancer\n",
    "import funlib.show.neuroglancer as funlibng\n",
    "import daisy\n",
    "import numpy as np\n",
    "\n",
    "# Replace my_ip with your public paperspace ip as shown in your browser\n",
    "my_ip = \"172.83.14.204\"\n",
    "neuroglancer.set_server_bind_address('0.0.0.0', 8889)\n",
    "\n",
    "data_file = './snapshots/00000000.hdf'\n",
    "affs_ds = daisy.open_ds(data_file, 'volumes/affinities')\n",
    "affs_ds.data = np.array(affs_ds.data, dtype=np.float32)\n",
    "labels_ds = daisy.open_ds(data_file, 'volumes/labels/neuron_ids')\n",
    "raw_ds = daisy.open_ds(data_file, 'volumes/raw')\n",
    "\n",
    "neuroglancer.set_server_bind_address('0.0.0.0')\n",
    "viewer = neuroglancer.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    funlibng.add_layer(s, raw_ds, 'raw')\n",
    "    funlibng.add_layer(s, labels_ds, 'labels')\n",
    "    funlibng.add_layer(s, affs_ds, 'affinities', shader='rgb')\n",
    "\n",
    "print(viewer.__str__().replace(\"localhost\", my_ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## Using gunpowder with tensorflow for training a 3D-UNet for affinity prediction\n",
    "#### mknet.py\n",
    "\n",
    "In this exercise we ask you to fill in the given template file to create a computation graph for your neural network. Follow the instructions in the code and make use of help and documentations. \n",
    "\n",
    "As usual if you are not sure about what a function does or what its argument is navigate to the function and press ```shift + tab``` to display arguments and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating U-Net layer 0\n",
      "f_in: (1, 1, 84, 268, 268)\n",
      "number of variables added: 4236, new total: 4236\n",
      "    Creating U-Net layer 1\n",
      "    f_in: (1, 12, 80, 88, 88)\n",
      "    number of variables added: 116760, new total: 120996\n",
      "        Creating U-Net layer 2\n",
      "        f_in: (1, 60, 76, 28, 28)\n",
      "        number of variables added: 2916600, new total: 3037596\n",
      "            Creating U-Net layer 3\n",
      "            f_in: (1, 300, 24, 8, 8)\n",
      "            bottom layer\n",
      "            f_out: (1, 1500, 20, 4, 4)\n",
      "            number of variables added: 72903000, new total: 75940596\n",
      "        g_out: (1, 1500, 20, 4, 4)\n",
      "        g_out_upsampled: (1, 300, 60, 12, 12)\n",
      "        f_left_cropped: (1, 300, 60, 12, 12)\n",
      "        f_right: (1, 600, 60, 12, 12)\n",
      "        f_out: (1, 300, 56, 8, 8)\n",
      "        number of variables added: 19440900, new total: 95381496\n",
      "    g_out: (1, 300, 56, 8, 8)\n",
      "    g_out_upsampled: (1, 60, 56, 24, 24)\n",
      "    f_left_cropped: (1, 60, 56, 24, 24)\n",
      "    f_right: (1, 120, 56, 24, 24)\n",
      "    f_out: (1, 60, 52, 20, 20)\n",
      "    number of variables added: 453780, new total: 95835276\n",
      "g_out: (1, 60, 52, 20, 20)\n",
      "g_out_upsampled: (1, 12, 52, 60, 60)\n",
      "f_left_cropped: (1, 12, 52, 60, 60)\n",
      "f_right: (1, 24, 52, 60, 60)\n",
      "f_out: (1, 12, 48, 56, 56)\n",
      "number of variables added: 18180, new total: 95853456\n",
      "WARNING:tensorflow:From /groups/funke/home/ecksteinn/miniconda2/envs/segmentation/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "input shape : (84, 268, 268)\n",
      "output shape: [48, 56, 56]\n",
      "Creating U-Net layer 0\n",
      "f_in: (1, 1, 114, 646, 646)\n",
      "number of variables added: 4236, new total: 4236\n",
      "    Creating U-Net layer 1\n",
      "    f_in: (1, 12, 110, 214, 214)\n",
      "    number of variables added: 116760, new total: 120996\n",
      "        Creating U-Net layer 2\n",
      "        f_in: (1, 60, 106, 70, 70)\n",
      "        number of variables added: 2916600, new total: 3037596\n",
      "            Creating U-Net layer 3\n",
      "            f_in: (1, 300, 34, 22, 22)\n",
      "            bottom layer\n",
      "            f_out: (1, 1500, 30, 18, 18)\n",
      "            number of variables added: 72903000, new total: 75940596\n",
      "        g_out: (1, 1500, 30, 18, 18)\n",
      "        g_out_upsampled: (1, 300, 90, 54, 54)\n",
      "        f_left_cropped: (1, 300, 90, 54, 54)\n",
      "        f_right: (1, 600, 90, 54, 54)\n",
      "        f_out: (1, 300, 86, 50, 50)\n",
      "        number of variables added: 19440900, new total: 95381496\n",
      "    g_out: (1, 300, 86, 50, 50)\n",
      "    g_out_upsampled: (1, 60, 86, 150, 150)\n",
      "    f_left_cropped: (1, 60, 86, 150, 150)\n",
      "    f_right: (1, 120, 86, 150, 150)\n",
      "    f_out: (1, 60, 82, 146, 146)\n",
      "    number of variables added: 453780, new total: 95835276\n",
      "g_out: (1, 60, 82, 146, 146)\n",
      "g_out_upsampled: (1, 12, 82, 438, 438)\n",
      "f_left_cropped: (1, 12, 82, 438, 438)\n",
      "f_right: (1, 24, 82, 438, 438)\n",
      "f_out: (1, 12, 78, 434, 434)\n",
      "number of variables added: 18180, new total: 95853456\n",
      "input shape : (114, 646, 646)\n",
      "output shape: [78, 434, 434]\n"
     ]
    }
   ],
   "source": [
    "from funlib.learn.tensorflow import models\n",
    "import malis\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "def create_network(input_shape, name):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.variable_scope('setup0'):\n",
    "\n",
    "        raw = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        raw_batched = tf.reshape(raw, (1, 1) + input_shape)\n",
    "        \n",
    "        \"\"\"\n",
    "        Define your model architecture here:\n",
    "        \n",
    "        1. Set the main model parameters for the UNet:\n",
    "        \n",
    "        unet, _, _ = models.unet(...)\n",
    "        \n",
    "        2. Generate the desired number of output features (3 for affinities in z,y,x direction)\n",
    "           by using a convolution with kernel size 1:\n",
    "           \n",
    "        affs_batched = models.conv_pass(unet, ...)\n",
    "        \"\"\"\n",
    "\n",
    "        output_shape_batched = affs_batched.get_shape().as_list()\n",
    "        output_shape = output_shape_batched[1:] # strip the batch dimension\n",
    "\n",
    "        affs = tf.reshape(affs_batched, output_shape)\n",
    "\n",
    "        gt_affs = tf.placeholder(tf.float32, shape=output_shape)\n",
    "        affs_loss_weights = tf.placeholder(tf.float32, shape=output_shape)\n",
    "        \n",
    "        \"\"\"\n",
    "        Define your loss here. For reference see tensorflow.losses documentation.\n",
    "        \n",
    "        loss = ...\n",
    "        \"\"\"\n",
    "        \n",
    "        loss = tf.losses.mean_squared_error(\n",
    "            gt_affs,\n",
    "            affs,\n",
    "            affs_loss_weights)\n",
    "\n",
    "        # Generate a summary for tensorboard:\n",
    "        summary = tf.summary.scalar('setup0', loss)\n",
    "\n",
    "        \"\"\"\n",
    "        Choose an optimizer and learning parameters. Minimize the loss.\n",
    "        For reference see tensorflow.train\n",
    "        \n",
    "        opt = ...\n",
    "        optimizer = opt.minimize(loss)\n",
    "        \"\"\"\n",
    "\n",
    "        output_shape = output_shape[1:]\n",
    "        print(\"input shape : %s\"%(input_shape,))\n",
    "        print(\"output shape: %s\"%(output_shape,))\n",
    "\n",
    "        # Export your computation graph:\n",
    "        tf.train.export_meta_graph(filename=name + '.meta')\n",
    "\n",
    "        # Write out the names of relevant tensors in this graph s.t. the train script can feed and receive values.\n",
    "        config = {\n",
    "            'raw': raw.name,\n",
    "            'affs': affs.name,\n",
    "            'gt_affs': gt_affs.name,\n",
    "            'affs_loss_weights': affs_loss_weights.name,\n",
    "            'loss': loss.name,\n",
    "            'optimizer': optimizer.name,\n",
    "            'input_shape': input_shape,\n",
    "            'output_shape': output_shape,\n",
    "            'summary': summary.name\n",
    "        }\n",
    "\n",
    "        config['outputs'] = {'affs': {\"out_dims\": 3, \"out_dtype\": \"uint8\"}}\n",
    "\n",
    "        with open(name + '.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the script and produce the necessary files for training:\n",
    "    create_network((84, 268, 268), 'train_net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "## A gunpowder training pipeline\n",
    "\n",
    "In this exercise we ask you to use gunpowder in combination with tensorflow to build a training pipeline for affinity prediction. Fill in the gaps in the template code below and train your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gunpowder.tensorflow.local_server:Creating local tensorflow server\n",
      "INFO:gunpowder.tensorflow.local_server:Server running at b'grpc://localhost:36769'\n",
      "INFO:gunpowder.tensorflow.nodes.train:Initializing tf session, connecting to b'grpc://localhost:36769'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT:  (960, 112, 112)\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gunpowder.tensorflow.nodes.train:Reading meta-graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /groups/funke/home/ecksteinn/miniconda2/envs/segmentation/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /groups/funke/home/ecksteinn/miniconda2/envs/segmentation/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:gunpowder.tensorflow.nodes.train:No checkpoint found\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "from gunpowder import *\n",
    "from gunpowder.tensorflow import *\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "# Adapt the path to where the training data is stored:\n",
    "data_dir = '../../jan/segmentation/data'\n",
    "\n",
    "samples = [\n",
    "    'sample_A',\n",
    "    'sample_B',\n",
    "    'sample_C'\n",
    "]\n",
    "\n",
    "# This defines how we calculate affinities, in this case we consider direct neighbours in z,y,x direction:\n",
    "neighborhood = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]\n",
    "\n",
    "def train_until(max_iteration):\n",
    "\n",
    "    if tf.train.latest_checkpoint('.'):\n",
    "        trained_until = int(tf.train.latest_checkpoint('.').split('_')[-1])\n",
    "    else:\n",
    "        trained_until = 0\n",
    "    if trained_until >= max_iteration:\n",
    "        return\n",
    "\n",
    "    # Load tensor names from the file you generated above:\n",
    "    with open('train_net.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Define gunpowder variables of interest\n",
    "    raw = ArrayKey('RAW')\n",
    "    labels = ArrayKey('GT_LABELS')\n",
    "    labels_mask = ArrayKey('GT_LABELS_MASK')\n",
    "    affs = ArrayKey('PREDICTED_AFFS')\n",
    "    gt = ArrayKey('GT_AFFINITIES')\n",
    "    gt_mask = ArrayKey('GT_AFFINITIES_MASK')\n",
    "    gt_scale = ArrayKey('GT_AFFINITIES_SCALE')\n",
    "    affs_gradient = ArrayKey('AFFS_GRADIENT')\n",
    "\n",
    "    voxel_size = Coordinate((40, 4, 4))\n",
    "    input_size = Coordinate(config['input_shape'])*voxel_size\n",
    "    output_size = Coordinate(config['output_shape'])*voxel_size\n",
    "    context = output_size/2\n",
    "    print('CONTEXT: ', context)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Build the actual data loading and train pipeline by chaining\n",
    "    gunpowder nodes. Each gunpowder node provides an atomic operation \n",
    "    and can request data from upstream nodes. For reference see:\n",
    "    https://github.com/funkey/gunpowder\n",
    "    \n",
    "    In the following we provide you with a skeleton\n",
    "    pipeline. You should add the actual training node, data preprocessing nodes and \n",
    "    data augmentation nodes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Request all the data you need for training:\n",
    "    request = BatchRequest()\n",
    "    request.add(raw, input_size)\n",
    "    request.add(labels, output_size)\n",
    "    request.add(labels_mask, output_size)\n",
    "    request.add(gt, output_size)\n",
    "    request.add(gt_mask, output_size)\n",
    "    request.add(gt_scale, output_size)\n",
    "\n",
    "    # Request a snapshot s.t. you are able to visualize the data used and produced during training.\n",
    "    snapshot_request = BatchRequest({\n",
    "        affs: request[gt],\n",
    "        affs_gradient: request[gt]\n",
    "    })\n",
    "\n",
    "    # Define a data source. In this case the data we provide contains \n",
    "    # raw EM images together with neuron segments (neuron_ids)\n",
    "    # and a mask for regions in the EM data that should not contribute towards \n",
    "    # training.\n",
    "    data_sources = tuple(\n",
    "        N5Source(\n",
    "            os.path.join(data_dir, sample + '.n5'),\n",
    "            datasets = {\n",
    "                raw: 'volumes/raw',\n",
    "                labels: 'volumes/labels/neuron_ids',\n",
    "                labels_mask: 'volumes/labels/mask',\n",
    "            },\n",
    "            array_specs = {\n",
    "                raw: ArraySpec(interpolatable=True),\n",
    "                labels: ArraySpec(interpolatable=False),\n",
    "                labels_mask: ArraySpec(interpolatable=False)\n",
    "            }\n",
    "        ) +\n",
    "        Normalize(raw) + \n",
    "        Pad(labels, context) +\n",
    "        Pad(labels_mask, context) +\n",
    "        RandomLocation() +\n",
    "        Reject(mask=labels_mask)\n",
    "        for sample in samples\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    Define the actual train pipeline here:\n",
    "    \n",
    "    train_pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        ```Add elastic augmentation``` +\n",
    "        ```Add simple augmentation``` + \n",
    "        ```Add intensity augmentation``` +\n",
    "        GrowBoundary(labels, labels_mask, steps=1, only_xy=True) +\n",
    "        ```So far the data sources only provide neuron labels\n",
    "            and the raw em data. We need to generate the actual training\n",
    "            data which are affinities. Add a node that does this here.``` +\n",
    "        BalanceLabels(\n",
    "            gt,\n",
    "            gt_scale,\n",
    "            gt_mask) +\n",
    "        ```Add defect augment without artifacts```\n",
    "        IntensityScaleShift(raw, 2,-1) +\n",
    "        PreCache(cache_size=40,\n",
    "                 num_workers=10) +\n",
    "        ```\n",
    "        Add the actual Train node here:\n",
    "        Train(...) +\n",
    "        ```\n",
    "        IntensityScaleShift(raw, 0.5, 0.5) +\n",
    "        Snapshot({\n",
    "                raw: 'volumes/raw',\n",
    "                labels: 'volumes/labels/neuron_ids',\n",
    "                gt: 'volumes/gt_affinities',\n",
    "                affs: 'volumes/pred_affinities',\n",
    "                gt_mask: 'volumes/labels/gt_mask',\n",
    "                labels_mask: 'volumes/labels/mask',\n",
    "                affs_gradient: 'volumes/affs_gradient'\n",
    "            },\n",
    "            dataset_dtypes={\n",
    "                labels: np.uint64\n",
    "            },\n",
    "            every=1000,\n",
    "            output_filename='batch_{iteration}.hdf',\n",
    "            additional_request=snapshot_request) +\n",
    "        PrintProfilingStats(every=10)\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    \"\"\"\n",
    "    Implement the train loop:\n",
    "    with build(train_pipeline) as b:\n",
    "        ...\n",
    "    \"\"\"\n",
    "    print(\"Training finished\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iteration = 500000\n",
    "    train_until(iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "## Monitor the training progress\n",
    "\n",
    "Visualize the generated training snapshots with neuroglancer and observe loss curves using tensorboard.\n",
    "\n",
    "\n",
    "#### Snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroglancer\n",
    "import funlib.show.neuroglancer as funlibng\n",
    "import daisy\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Replace the path for the data file with the snapshot you want to visualize. \n",
    "\n",
    "data_file = ...\n",
    "\"\"\"\n",
    "\n",
    "gt_affs_ds = daisy.open_ds(data_file, 'volumes/gt_affinities')\n",
    "gt_affs_ds.data = np.array(gt_affs_ds.data, dtype=np.float32)\n",
    "\n",
    "pred_affs_ds = daisy.open_ds(data_file, 'volumes/pred_affinities')\n",
    "pred_affs_ds.data = np.array(pred_affs_ds.data, dtype=np.float32)\n",
    "\n",
    "gradients_ds = daisy.open_ds(data_file, 'volumes/affs_gradient')\n",
    "\n",
    "labels_ds = daisy.open_ds(data_file, 'volumes/labels/neuron_ids')\n",
    "raw_ds = daisy.open_ds(data_file, 'volumes/raw')\n",
    "\n",
    "# Replace my_ip with your public paperspace ip as shown in your browser\n",
    "my_ip = \"172.83.14.204\"\n",
    "neuroglancer.set_server_bind_address('0.0.0.0', 8889)\n",
    "\n",
    "viewer = neuroglancer.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    funlibng.add_layer(s, raw_ds, 'raw')\n",
    "    funlibng.add_layer(s, labels_ds, 'labels')\n",
    "    funlibng.add_layer(s, gt_affs_ds, 'gt_affinities', shader='rgb')\n",
    "    funlibng.add_layer(s, pred_affs_ds, 'pred_affinities', shader='rgb')\n",
    "    funlibng.add_layer(s, gradients_ds, 'gradients')\n",
    "\n",
    "print(viewer.__str__().replace(\"localhost\", my_ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss\n",
    "To visualize your loss using tensorboard open a terminal and execute: \n",
    "```tensorboard --logdir=path/to/log-directory```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
