{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0.1\n",
    "## Introduction to EM data, neuron segmentation and gunpowder\n",
    "### A simple gunpowder example pipeline for loading and manipulating data\n",
    "\n",
    "Become familiar with gunpowder. Read and try to understand the following code as well as the general principle behind gunpowder. Read the introductory example in the gunpowder documentation http://funkey.science/gunpowder and gunpowder tutorial http://funkey.science/gunpowder/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from gunpowder import *\n",
    "from gunpowder.tensorflow import *\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# A simple gunpowder pipeline for loading and manipulating data:\n",
    "data_dir = '../../jan/segmentation/data'\n",
    "\n",
    "samples = [\n",
    "    'sample_A',\n",
    "    'sample_B',\n",
    "    'sample_C'\n",
    "]\n",
    "\n",
    "\n",
    "# Define gunpowder variables of interest:\n",
    "raw = ArrayKey('RAW') # Raw EM data\n",
    "labels = ArrayKey('GT_LABELS') # ground truth neuron segmentation \n",
    "affinities = ArrayKey('GT_AFFINITIES') # affinities\n",
    "\n",
    "# Voxel size is the physical size of one voxel (=3D pixel) in nm.\n",
    "voxel_size = Coordinate((40, 4, 4))\n",
    "batch_size = Coordinate((30,1000,1000)) * voxel_size\n",
    "\n",
    "# Request all the data you need for training:\n",
    "request = BatchRequest()\n",
    "request.add(raw, batch_size)\n",
    "request.add(labels, batch_size)\n",
    "request.add(affinities, batch_size)\n",
    "\n",
    "# Request a snapshot s.t. you are able to visualize the data in your pipeline.\n",
    "snapshot_request = BatchRequest({\n",
    "    raw: request[raw],\n",
    "    labels: request[labels],\n",
    "    affinities: request[affinities]\n",
    "})\n",
    "\n",
    "# Note that the data only provides raw and neuron_ids which is the neuron segmentation.\n",
    "# However, we need affinities which we can generate from neuron_ids by using gunpowder (see below):\n",
    "data_sources = tuple(\n",
    "    N5Source(\n",
    "        os.path.join(data_dir, sample + '.n5'),\n",
    "        datasets = {\n",
    "            raw: 'volumes/raw',\n",
    "            labels: 'volumes/labels/neuron_ids',\n",
    "        },\n",
    "        array_specs = {\n",
    "            raw: ArraySpec(interpolatable=True),\n",
    "            labels: ArraySpec(interpolatable=False)\n",
    "        }\n",
    "    ) +\n",
    "    Normalize(raw) + \n",
    "    RandomLocation()\n",
    "    for sample in samples\n",
    "    )\n",
    "\n",
    "\n",
    "# Define a neighborhood for affinities:\n",
    "neighborhood = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]\n",
    "\n",
    "pipeline = (\n",
    "    data_sources +\n",
    "    RandomProvider() +\n",
    "    AddAffinities(neighborhood,\n",
    "                 labels=labels,\n",
    "                 affinities=affinities) +\n",
    "    Snapshot({raw: 'volumes/raw',\n",
    "              labels: 'volumes/labels/neuron_ids',\n",
    "              affinities: 'volumes/affinities'}))\n",
    "    \n",
    "    \n",
    "with build(pipeline) as b:\n",
    "    b.request_batch(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0.2 \n",
    "## Visualize data using neuroglancer\n",
    "\n",
    "Exercise 0.1 generated a file in your working directory containg the raw EM data, neuron segmentation and affinities. The following script lets you view the data. Run both cells below and click on the resulting link. You can enable and disable layers by clicking on them. Explore the data. What do the different colors of the affinities mean? How does it relate to the segmentation?\n",
    "\n",
    "If you double click on a particular segment neuroglancer allows you to view the 3D mesh of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = './snapshots/00000001.hdf', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-698436d39dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./snapshots/00000001.hdf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0maffs_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdaisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'volumes/affinities'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0maffs_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffs_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlabels_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdaisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'volumes/labels/neuron_ids'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/wh2019_segmentation/src/daisy/daisy/datasets.py\u001b[0m in \u001b[0;36mopen_ds\u001b[0;34m(filename, ds_name, mode)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"opening H5 dataset %s in %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mvoxel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_voxel_size_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = './snapshots/00000001.hdf', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import neuroglancer\n",
    "import funlib.show.neuroglancer as funlibng\n",
    "import daisy\n",
    "import numpy as np\n",
    "\n",
    "# Replace my_ip with your public paperspace ip as shown in your browser\n",
    "my_ip = \"172.83.14.204\"\n",
    "neuroglancer.set_server_bind_address('0.0.0.0', 8889)\n",
    "\n",
    "data_file = './snapshots/00000001.hdf'\n",
    "affs_ds = daisy.open_ds(data_file, 'volumes/affinities')\n",
    "affs_ds.data = np.array(affs_ds.data, dtype=np.float32)\n",
    "labels_ds = daisy.open_ds(data_file, 'volumes/labels/neuron_ids')\n",
    "raw_ds = daisy.open_ds(data_file, 'volumes/raw')\n",
    "\n",
    "neuroglancer.set_server_bind_address('0.0.0.0')\n",
    "viewer = neuroglancer.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    funlibng.add_layer(s, raw_ds, 'raw')\n",
    "    funlibng.add_layer(s, labels_ds, 'labels')\n",
    "    funlibng.add_layer(s, affs_ds, 'affinities', shader='rgb')\n",
    "\n",
    "print(viewer.__str__().replace(\"localhost\", my_ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0.3\n",
    "## Extend the data manipulation pipeline from before by adding data augmentations. \n",
    "\n",
    "Observe how different augmentations and parameters thereof change the output by visualizing your data with neuroglancer.\n",
    "\n",
    "An example of how to use augmentation is given below. Play around with augmentation parameters and add more augmentation types. For more information about what type of augmentations are available in gunpowder see: http://funkey.science/gunpowder/api.html#augmentation-nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from gunpowder import *\n",
    "from gunpowder.tensorflow import *\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "# A simple gunpowder pipeline for loading and manipulating data:\n",
    "data_dir = '../../jan/segmentation/data'\n",
    "\n",
    "samples = [\n",
    "    'sample_A',\n",
    "    'sample_B',\n",
    "    'sample_C'\n",
    "]\n",
    "\n",
    "\n",
    "# Define gunpowder variables of interest:\n",
    "raw = ArrayKey('RAW') # Raw EM data\n",
    "labels = ArrayKey('GT_LABELS') # ground truth neuron segmentation \n",
    "affinities = ArrayKey('GT_AFFINITIES') # affinities\n",
    "\n",
    "# Voxel size is the physical size of one voxel (=3D pixel) in nm.\n",
    "voxel_size = Coordinate((40, 4, 4))\n",
    "batch_size = Coordinate((30,1000,1000)) * voxel_size\n",
    "\n",
    "# Request all the data you need for training:\n",
    "request = BatchRequest()\n",
    "request.add(raw, batch_size)\n",
    "request.add(labels, batch_size)\n",
    "request.add(affinities, batch_size)\n",
    "\n",
    "# Request a snapshot s.t. you are able to visualize the data in your pipeline.\n",
    "snapshot_request = BatchRequest({\n",
    "    raw: request[raw],\n",
    "    labels: request[labels],\n",
    "    affinities: request[affinities]\n",
    "})\n",
    "\n",
    "# Note that the data only provides raw and neuron_ids which is the neuron segmentation.\n",
    "# However, we need affinities which we can generate from neuron_ids by using gunpowder (see below):\n",
    "data_sources = tuple(\n",
    "    N5Source(\n",
    "        os.path.join(data_dir, sample + '.n5'),\n",
    "        datasets = {\n",
    "            raw: 'volumes/raw',\n",
    "            labels: 'volumes/labels/neuron_ids',\n",
    "        },\n",
    "        array_specs = {\n",
    "            raw: ArraySpec(interpolatable=True),\n",
    "            labels: ArraySpec(interpolatable=False)\n",
    "        }\n",
    "    ) +\n",
    "    Normalize(raw) + \n",
    "    RandomLocation()\n",
    "    for sample in samples\n",
    "    )\n",
    "\n",
    "\n",
    "# Define a neighborhood for affinities:\n",
    "neighborhood = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]\n",
    "\n",
    "pipeline = (\n",
    "    data_sources +\n",
    "    RandomProvider() +\n",
    "    ElasticAugment(\n",
    "            control_point_spacing=[4,40,40],\n",
    "            jitter_sigma=[0,2,2],\n",
    "            rotation_interval=[0,math.pi/2.0],\n",
    "            prob_slip=0.05,\n",
    "            prob_shift=0.05,\n",
    "            max_misalign=10,\n",
    "            subsample=8) +\n",
    "    SimpleAugment(transpose_only=[1, 2]) +\n",
    "    IntensityAugment(raw, 0.9, 1.1, -0.1, 0.1, z_section_wise=True) +\n",
    "    AddAffinities(neighborhood,\n",
    "                 labels=labels,\n",
    "                 affinities=affinities) +\n",
    "    Snapshot({raw: 'volumes/raw',\n",
    "              labels: 'volumes/labels/neuron_ids',\n",
    "              affinities: 'volumes/affinities'}))\n",
    "    \n",
    "    \n",
    "with build(pipeline) as b:\n",
    "    b.request_batch(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## Using gunpowder with tensorflow for training a 3D-UNet for affinity prediction\n",
    "#### mknet.py\n",
    "\n",
    "In this exercise we ask you to fill in the given template file to create a computation graph for your neural network. Follow the instructions in the code and make use of help and documentations.\n",
    "\n",
    "As usual if you are not sure about what a function does or what its argument is navigate to the function and press ```shift + tab``` to display arguments and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating U-Net layer 0\n",
      "f_in: (1, 1, 84, 268, 268)\n",
      "number of variables added: 4236, new total: 4236\n",
      "    Creating U-Net layer 1\n",
      "    f_in: (1, 12, 80, 88, 88)\n",
      "    number of variables added: 116760, new total: 120996\n",
      "        Creating U-Net layer 2\n",
      "        f_in: (1, 60, 76, 28, 28)\n",
      "        number of variables added: 2916600, new total: 3037596\n",
      "            Creating U-Net layer 3\n",
      "            f_in: (1, 300, 24, 8, 8)\n",
      "            bottom layer\n",
      "            f_out: (1, 1500, 20, 4, 4)\n",
      "            number of variables added: 72903000, new total: 75940596\n",
      "        g_out: (1, 1500, 20, 4, 4)\n",
      "        g_out_upsampled: (1, 300, 60, 12, 12)\n",
      "        f_left_cropped: (1, 300, 60, 12, 12)\n",
      "        f_right: (1, 600, 60, 12, 12)\n",
      "        f_out: (1, 300, 56, 8, 8)\n",
      "        number of variables added: 19440900, new total: 95381496\n",
      "    g_out: (1, 300, 56, 8, 8)\n",
      "    g_out_upsampled: (1, 60, 56, 24, 24)\n",
      "    f_left_cropped: (1, 60, 56, 24, 24)\n",
      "    f_right: (1, 120, 56, 24, 24)\n",
      "    f_out: (1, 60, 52, 20, 20)\n",
      "    number of variables added: 453780, new total: 95835276\n",
      "g_out: (1, 60, 52, 20, 20)\n",
      "g_out_upsampled: (1, 12, 52, 60, 60)\n",
      "f_left_cropped: (1, 12, 52, 60, 60)\n",
      "f_right: (1, 24, 52, 60, 60)\n",
      "f_out: (1, 12, 48, 56, 56)\n",
      "number of variables added: 18180, new total: 95853456\n",
      "WARNING:tensorflow:From /groups/funke/home/ecksteinn/miniconda2/envs/segmentation/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "input shape : (84, 268, 268)\n",
      "output shape: [48, 56, 56]\n",
      "Creating U-Net layer 0\n",
      "f_in: (1, 1, 114, 646, 646)\n",
      "number of variables added: 4236, new total: 4236\n",
      "    Creating U-Net layer 1\n",
      "    f_in: (1, 12, 110, 214, 214)\n",
      "    number of variables added: 116760, new total: 120996\n",
      "        Creating U-Net layer 2\n",
      "        f_in: (1, 60, 106, 70, 70)\n",
      "        number of variables added: 2916600, new total: 3037596\n",
      "            Creating U-Net layer 3\n",
      "            f_in: (1, 300, 34, 22, 22)\n",
      "            bottom layer\n",
      "            f_out: (1, 1500, 30, 18, 18)\n",
      "            number of variables added: 72903000, new total: 75940596\n",
      "        g_out: (1, 1500, 30, 18, 18)\n",
      "        g_out_upsampled: (1, 300, 90, 54, 54)\n",
      "        f_left_cropped: (1, 300, 90, 54, 54)\n",
      "        f_right: (1, 600, 90, 54, 54)\n",
      "        f_out: (1, 300, 86, 50, 50)\n",
      "        number of variables added: 19440900, new total: 95381496\n",
      "    g_out: (1, 300, 86, 50, 50)\n",
      "    g_out_upsampled: (1, 60, 86, 150, 150)\n",
      "    f_left_cropped: (1, 60, 86, 150, 150)\n",
      "    f_right: (1, 120, 86, 150, 150)\n",
      "    f_out: (1, 60, 82, 146, 146)\n",
      "    number of variables added: 453780, new total: 95835276\n",
      "g_out: (1, 60, 82, 146, 146)\n",
      "g_out_upsampled: (1, 12, 82, 438, 438)\n",
      "f_left_cropped: (1, 12, 82, 438, 438)\n",
      "f_right: (1, 24, 82, 438, 438)\n",
      "f_out: (1, 12, 78, 434, 434)\n",
      "number of variables added: 18180, new total: 95853456\n",
      "input shape : (114, 646, 646)\n",
      "output shape: [78, 434, 434]\n"
     ]
    }
   ],
   "source": [
    "from funlib.learn.tensorflow import models\n",
    "import malis\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "def create_network(input_shape, name):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.variable_scope('setup0'):\n",
    "\n",
    "        raw = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        raw_batched = tf.reshape(raw, (1, 1) + input_shape)\n",
    "\n",
    "        unet, _, _ = models.unet(\n",
    "                raw_batched,\n",
    "                12,\n",
    "                5,\n",
    "                [[1,3,3],[1,3,3],[3,3,3]])\n",
    "\n",
    "        affs_batched, _ = models.conv_pass(\n",
    "            unet,\n",
    "            kernel_sizes=[1],\n",
    "            num_fmaps=3,\n",
    "            activation='sigmoid',\n",
    "            name='affs')\n",
    "\n",
    "        output_shape_batched = affs_batched.get_shape().as_list()\n",
    "        output_shape = output_shape_batched[1:] # strip the batch dimension\n",
    "\n",
    "        affs = tf.reshape(affs_batched, output_shape)\n",
    "\n",
    "        gt_affs = tf.placeholder(tf.float32, shape=output_shape)\n",
    "        affs_loss_weights = tf.placeholder(tf.float32, shape=output_shape)\n",
    "\n",
    "        loss = tf.losses.mean_squared_error(\n",
    "            gt_affs,\n",
    "            affs,\n",
    "            affs_loss_weights)\n",
    "\n",
    "        summary = tf.summary.scalar('setup0', loss)\n",
    "\n",
    "        opt = tf.train.AdamOptimizer(\n",
    "            learning_rate=0.5e-4,\n",
    "            beta1=0.95,\n",
    "            beta2=0.999,\n",
    "            epsilon=1e-8)\n",
    "        optimizer = opt.minimize(loss)\n",
    "\n",
    "        output_shape = output_shape[1:]\n",
    "        print(\"input shape : %s\"%(input_shape,))\n",
    "        print(\"output shape: %s\"%(output_shape,))\n",
    "\n",
    "        tf.train.export_meta_graph(filename=name + '.meta')\n",
    "\n",
    "        config = {\n",
    "            'raw': raw.name,\n",
    "            'affs': affs.name,\n",
    "            'gt_affs': gt_affs.name,\n",
    "            'affs_loss_weights': affs_loss_weights.name,\n",
    "            'loss': loss.name,\n",
    "            'optimizer': optimizer.name,\n",
    "            'input_shape': input_shape,\n",
    "            'output_shape': output_shape,\n",
    "            'summary': summary.name\n",
    "        }\n",
    "\n",
    "        config['outputs'] = {'affs': {\"out_dims\": 3, \"out_dtype\": \"uint8\"}}\n",
    "\n",
    "        with open(name + '.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_network((84, 268, 268), 'train_net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "## A gunpowder training pipeline\n",
    "\n",
    "In this exercise we ask you to use gunpowder in combination with tensorflow to build a training pipeline for affinity prediction. Fill in the gaps in the template code below and train your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gunpowder.tensorflow.local_server:Creating local tensorflow server\n",
      "INFO:gunpowder.tensorflow.local_server:Server running at b'grpc://localhost:36769'\n",
      "INFO:gunpowder.tensorflow.nodes.train:Initializing tf session, connecting to b'grpc://localhost:36769'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT:  (960, 112, 112)\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gunpowder.tensorflow.nodes.train:Reading meta-graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /groups/funke/home/ecksteinn/miniconda2/envs/segmentation/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /groups/funke/home/ecksteinn/miniconda2/envs/segmentation/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:gunpowder.tensorflow.nodes.train:No checkpoint found\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#import multiprocessing\n",
    "#multiprocessing.set_start_method('forkserver')\n",
    "import sys\n",
    "from gunpowder import *\n",
    "from gunpowder.tensorflow import *\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "data_dir = '../../jan/segmentation/data'\n",
    "\n",
    "samples = [\n",
    "    'sample_A',\n",
    "    'sample_B',\n",
    "    'sample_C'\n",
    "]\n",
    "\n",
    "neighborhood = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]\n",
    "\n",
    "def train_until(max_iteration):\n",
    "\n",
    "    if tf.train.latest_checkpoint('.'):\n",
    "        trained_until = int(tf.train.latest_checkpoint('.').split('_')[-1])\n",
    "    else:\n",
    "        trained_until = 0\n",
    "    if trained_until >= max_iteration:\n",
    "        return\n",
    "\n",
    "    with open('train_net.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    raw = ArrayKey('RAW')\n",
    "    labels = ArrayKey('GT_LABELS')\n",
    "    labels_mask = ArrayKey('GT_LABELS_MASK')\n",
    "    affs = ArrayKey('PREDICTED_AFFS')\n",
    "    gt = ArrayKey('GT_AFFINITIES')\n",
    "    gt_mask = ArrayKey('GT_AFFINITIES_MASK')\n",
    "    gt_scale = ArrayKey('GT_AFFINITIES_SCALE')\n",
    "    affs_gradient = ArrayKey('AFFS_GRADIENT')\n",
    "\n",
    "    voxel_size = Coordinate((40, 4, 4))\n",
    "    input_size = Coordinate(config['input_shape'])*voxel_size\n",
    "    output_size = Coordinate(config['output_shape'])*voxel_size\n",
    "    context = output_size/2\n",
    "    print('CONTEXT: ', context)\n",
    "\n",
    "    request = BatchRequest()\n",
    "    request.add(raw, input_size)\n",
    "    request.add(labels, output_size)\n",
    "    request.add(labels_mask, output_size)\n",
    "    request.add(gt, output_size)\n",
    "    request.add(gt_mask, output_size)\n",
    "    request.add(gt_scale, output_size)\n",
    "\n",
    "    snapshot_request = BatchRequest({\n",
    "        affs: request[gt],\n",
    "        affs_gradient: request[gt]\n",
    "    })\n",
    "\n",
    "    data_sources = tuple(\n",
    "        N5Source(\n",
    "            os.path.join(data_dir, sample + '.n5'),\n",
    "            datasets = {\n",
    "                raw: 'volumes/raw',\n",
    "                labels: 'volumes/labels/neuron_ids',\n",
    "                labels_mask: 'volumes/labels/mask',\n",
    "            },\n",
    "            array_specs = {\n",
    "                raw: ArraySpec(interpolatable=True),\n",
    "                labels: ArraySpec(interpolatable=False),\n",
    "                labels_mask: ArraySpec(interpolatable=False)\n",
    "            }\n",
    "        ) +\n",
    "        Normalize(raw) +\n",
    "        Pad(labels, context) +\n",
    "        Pad(labels_mask, context) +\n",
    "        RandomLocation() +\n",
    "        Reject(mask=labels_mask)\n",
    "        for sample in samples\n",
    "    )\n",
    "\n",
    "\n",
    "    train_pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        ElasticAugment(\n",
    "            control_point_spacing=[4,40,40],\n",
    "            jitter_sigma=[0,2,2],\n",
    "            rotation_interval=[0,math.pi/2.0],\n",
    "            prob_slip=0.05,\n",
    "            prob_shift=0.05,\n",
    "            max_misalign=10,\n",
    "            subsample=8) +\n",
    "        SimpleAugment(transpose_only=[1, 2]) +\n",
    "        IntensityAugment(raw, 0.9, 1.1, -0.1, 0.1, z_section_wise=True) +\n",
    "        GrowBoundary(labels, labels_mask, steps=1, only_xy=True) +\n",
    "        AddAffinities(\n",
    "            neighborhood,\n",
    "            labels=labels,\n",
    "            affinities=gt,\n",
    "            labels_mask=labels_mask,\n",
    "            affinities_mask=gt_mask) +\n",
    "        BalanceLabels(\n",
    "            gt,\n",
    "            gt_scale,\n",
    "            gt_mask) +\n",
    "        DefectAugment(\n",
    "            raw,\n",
    "            prob_missing=0.03,\n",
    "            prob_low_contrast=0.01,\n",
    "            contrast_scale=0.5,\n",
    "            axis=0) +\n",
    "        IntensityScaleShift(raw, 2,-1) +\n",
    "        PreCache(cache_size=40,\n",
    "                 num_workers=10) +\n",
    "        Train(\n",
    "            'train_net',\n",
    "            optimizer=config['optimizer'],\n",
    "            loss=config['loss'],\n",
    "            inputs={\n",
    "                config['raw']: raw,\n",
    "                config['gt_affs']: gt,\n",
    "                config['affs_loss_weights']: gt_scale,\n",
    "            },\n",
    "            outputs={\n",
    "                config['affs']: affs\n",
    "            },\n",
    "            gradients={\n",
    "                config['affs']: affs_gradient\n",
    "            },\n",
    "            summary=config['summary'],\n",
    "            log_dir='log',\n",
    "            save_every=10000) +\n",
    "        IntensityScaleShift(raw, 0.5, 0.5) +\n",
    "        Snapshot({\n",
    "                raw: 'volumes/raw',\n",
    "                labels: 'volumes/labels/neuron_ids',\n",
    "                gt: 'volumes/gt_affinities',\n",
    "                affs: 'volumes/pred_affinities',\n",
    "                gt_mask: 'volumes/labels/gt_mask',\n",
    "                labels_mask: 'volumes/labels/mask',\n",
    "                affs_gradient: 'volumes/affs_gradient'\n",
    "            },\n",
    "            dataset_dtypes={\n",
    "                labels: np.uint64\n",
    "            },\n",
    "            every=1000,\n",
    "            output_filename='batch_{iteration}.hdf',\n",
    "            additional_request=snapshot_request) +\n",
    "        PrintProfilingStats(every=10)\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    with build(train_pipeline) as b:\n",
    "        for i in range(max_iteration - trained_until):\n",
    "            b.request_batch(request)\n",
    "    print(\"Training finished\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    iteration = 500000\n",
    "    train_until(iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "## Monitor the training progress\n",
    "\n",
    "Visualize the generated training snapshots with neuroglancer and observe loss curves using tensorboard.\n",
    "\n",
    "\n",
    "#### Snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroglancer\n",
    "import funlib.show.neuroglancer as funlibng\n",
    "import daisy\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "data_file = ...\n",
    "\"\"\"\n",
    "\n",
    "gt_affs_ds = daisy.open_ds(data_file, 'volumes/gt_affinities')\n",
    "gt_affs_ds.data = np.array(gt_affs_ds.data, dtype=np.float32)\n",
    "\n",
    "pred_affs_ds = daisy.open_ds(data_file, 'volumes/pred_affinities')\n",
    "pred_affs_ds.data = np.array(pred_affs_ds.data, dtype=np.float32)\n",
    "\n",
    "gradients_ds = daisy.open_ds(data_file, 'volumes/affs_gradient')\n",
    "\n",
    "labels_ds = daisy.open_ds(data_file, 'volumes/labels/neuron_ids')\n",
    "raw_ds = daisy.open_ds(data_file, 'volumes/raw')\n",
    "\n",
    "# Replace my_ip with your public paperspace ip as shown in your browser\n",
    "my_ip = \"172.83.14.204\"\n",
    "neuroglancer.set_server_bind_address('0.0.0.0', 8889)\n",
    "\n",
    "viewer = neuroglancer.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    funlibng.add_layer(s, raw_ds, 'raw')\n",
    "    funlibng.add_layer(s, labels_ds, 'labels')\n",
    "    funlibng.add_layer(s, gt_affs_ds, 'gt_affinities', shader='rgb')\n",
    "    funlibng.add_layer(s, pred_affs_ds, 'pred_affinities', shader='rgb')\n",
    "    funlibng.add_layer(s, gradients_ds, 'gradients')\n",
    "\n",
    "print(viewer.__str__().replace(\"localhost\", my_ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss\n",
    "To visualize your loss using tensorboard open a terminal and execute: \n",
    "```tensorboard --logdir=path/to/log-directory```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:segmentation]",
   "language": "python",
   "name": "conda-env-segmentation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
