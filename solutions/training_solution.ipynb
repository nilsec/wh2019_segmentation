{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0.1\n",
    "## Introduction to EM data, neuron segmentation and gunpowder\n",
    "### A simple gunpowder example pipeline for loading and manipulating data\n",
    "\n",
    "Become familiar with gunpowder. Read and try to understand the following code as well as the general principle behind gunpowder. Read the introductory example in the gunpowder documentation http://funkey.science/gunpowder and gunpowder tutorial http://funkey.science/gunpowder/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from gunpowder import *\n",
    "from gunpowder.tensorflow import *\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# A simple gunpowder pipeline for loading and manipulating data:\n",
    "data_dir = '../../jan/segmentation/data'\n",
    "\n",
    "# Define gunpowder variables of interest:\n",
    "raw = ArrayKey('RAW') # Raw EM data\n",
    "labels = ArrayKey('GT_LABELS') # ground truth neuron segmentation \n",
    "affinities = ArrayKey('GT_AFFINITIES') # affinities\n",
    "\n",
    "# Voxel size is the physical size of one voxel (=3D pixel) in nm.\n",
    "voxel_size = Coordinate((40, 4, 4))\n",
    "batch_size = Coordinate((50,1000,1000)) * voxel_size\n",
    "\n",
    "# Request all the data you need for training:\n",
    "request = BatchRequest()\n",
    "request.add(raw, batch_size)\n",
    "request.add(labels, batch_size)\n",
    "request.add(affinities, batch_size)\n",
    "\n",
    "selec_roi = Roi(offset=(3000,5000,5100), shape=batch_size)\n",
    "request[raw].roi = selec_roi\n",
    "request[labels].roi = selec_roi\n",
    "request[affinities].roi = selec_roi\n",
    "\n",
    "# Request a snapshot s.t. you are able to visualize the data in your pipeline.\n",
    "snapshot_request = BatchRequest({\n",
    "    raw: request[raw],\n",
    "    labels: request[labels],\n",
    "    affinities: request[affinities]\n",
    "})\n",
    "\n",
    "# Note that the data only provides raw and neuron_ids which is the neuron segmentation.\n",
    "# However, we need affinities which we can generate from neuron_ids by using gunpowder (see below):\n",
    "data_sources = tuple(\n",
    "    N5Source(\n",
    "        os.path.join(data_dir, sample + '.n5'),\n",
    "        datasets = {\n",
    "            raw: 'volumes/raw',\n",
    "            labels: 'volumes/labels/neuron_ids',\n",
    "        },\n",
    "        array_specs = {\n",
    "            raw: ArraySpec(interpolatable=True),\n",
    "            labels: ArraySpec(interpolatable=False)\n",
    "        }\n",
    "    ) +\n",
    "    Normalize(raw)\n",
    "    for sample in [\"sample_C\"]\n",
    "    )\n",
    "\n",
    "# Define a neighborhood for affinities:\n",
    "neighborhood = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Build the actual data-pipeline:\n",
    "\n",
    "def basic_pipeline():\n",
    "    pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        AddAffinities(neighborhood,\n",
    "                     labels=labels,\n",
    "                     affinities=affinities) +\n",
    "        Snapshot(dataset_names={raw: 'volumes/raw',\n",
    "                  labels: 'volumes/labels/neuron_ids',\n",
    "                  affinities: 'volumes/affinities'},\n",
    "                  output_filename=\"snapshot_basic.hdf\"))\n",
    "    return pipeline\n",
    "\n",
    "def simple_augment_pipeline():\n",
    "    pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        SimpleAugment(transpose_only=[1, 2]) +\n",
    "        AddAffinities(neighborhood,\n",
    "                     labels=labels,\n",
    "                     affinities=affinities) +\n",
    "        Snapshot(dataset_names={raw: 'volumes/raw',\n",
    "                  labels: 'volumes/labels/neuron_ids',\n",
    "                  affinities: 'volumes/affinities'},\n",
    "                  output_filename=\"snapshot_simple.hdf\"))\n",
    "    return pipeline\n",
    "\n",
    "def intensity_augment_pipeline():\n",
    "    pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        IntensityAugment(raw, 0.9, 1.1, -0.1, 0.1, z_section_wise=True) +    \n",
    "        AddAffinities(neighborhood,\n",
    "                     labels=labels,\n",
    "                     affinities=affinities) +\n",
    "        Snapshot(dataset_names={raw: 'volumes/raw',\n",
    "                  labels: 'volumes/labels/neuron_ids',\n",
    "                  affinities: 'volumes/affinities'},\n",
    "                  output_filename=\"snapshot_intensity.hdf\"))\n",
    "    return pipeline\n",
    "\n",
    "def elastic_augment_pipeline():\n",
    "    pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        ElasticAugment(\n",
    "            control_point_spacing=[4,40,40],\n",
    "            jitter_sigma=[0,2,2],\n",
    "            rotation_interval=[0,math.pi/2.0],\n",
    "            prob_slip=0.05,\n",
    "            prob_shift=0.05,\n",
    "            max_misalign=10,\n",
    "            subsample=8) +\n",
    "        AddAffinities(neighborhood,\n",
    "                     labels=labels,\n",
    "                     affinities=affinities) +\n",
    "        Snapshot(dataset_names={raw: 'volumes/raw',\n",
    "                  labels: 'volumes/labels/neuron_ids',\n",
    "                  affinities: 'volumes/affinities'},\n",
    "                  output_filename=\"snapshot_elastic.hdf\"))\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "winter_is_coming=True\n",
    "def king_of_the_north():\n",
    "    pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        ElasticAugment(\n",
    "            control_point_spacing=[4,40,40],\n",
    "            jitter_sigma=[0,2,2],\n",
    "            rotation_interval=[0,math.pi/2.0],\n",
    "            prob_slip=0.05,\n",
    "            prob_shift=0.05,\n",
    "            max_misalign=10,\n",
    "            subsample=8) +\n",
    "        SimpleAugment(transpose_only=[1, 2]) +\n",
    "        IntensityAugment(raw, 0.9, 1.1, -0.1, 0.1, z_section_wise=True) +\n",
    "        AddAffinities(neighborhood,\n",
    "                     labels=labels,\n",
    "                     affinities=affinities) +\n",
    "        Snapshot(dataset_names={raw: 'volumes/raw',\n",
    "                  labels: 'volumes/labels/neuron_ids',\n",
    "                  affinities: 'volumes/affinities'},\n",
    "                  output_filename=\"snapshot_king.hdf\"))\n",
    "                      \n",
    "    return pipeline\n",
    "\n",
    "pipeline_setups={\"basic\": basic_pipeline,\n",
    "                 \"simple\": simple_augment_pipeline,\n",
    "                 \"intensity\": intensity_augment_pipeline,\n",
    "                 \"elastic\": elastic_augment_pipeline}\n",
    "\n",
    "if winter_is_coming:\n",
    "    pipeline_setups.update({\"king_of_the_north\": king_of_the_north})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a pipeline and understand how different augmentation types influence the output.\n",
    "\n",
    "### You can choose between:\n",
    "1. basic (No augmentations)\n",
    "2. simple\n",
    "3. intensity \n",
    "4. elastic\n",
    "5. (*If you implemented it: king_of_the_north)\n",
    "\n",
    "Try to find out what each of these are actually doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/.local/lib/python3.6/site-packages/scipy/ndimage/interpolation.py:605: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Choose a pipeline, run it and observe the differences in neuroglancer.\n",
    "pipeline_name = \"elastic\"\n",
    "\n",
    "\n",
    "pipeline_setup = pipeline_setups[pipeline_name]\n",
    "\n",
    "with build(pipeline_setup()) as b:\n",
    "    b.request_batch(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0.2 \n",
    "## Visualize data using neuroglancer\n",
    "\n",
    "Exercise 0.1 generated a file in your working directory containg the raw EM data, neuron segmentation and affinities. The following script lets you view the data you just generated and will change depending on which augmentation pipeline you choose. Run both cells below and click on the resulting link. You can enable and disable layers by clicking on them. Explore the data. What do the different colors of the affinities mean? How does it relate to the segmentation? How is augmentation affecting the data?\n",
    "\n",
    "If you double click on a particular segment neuroglancer allows you to view the 3D mesh of the object.\n",
    "\n",
    "### Dataset:\n",
    "The data you are looking at are a tiny subset of the **whole** adult Drosophila brain, imaged via serial section transmission electron microscopy (SSTEM) ([Zheng et al. 2018](https://www.sciencedirect.com/science/article/pii/S0092867418307876)). If you are curious and want to get a sense of the scale, [here](https://fafb.catmaid.virtualflybrain.org/?pid=1&zp=127040&yp=253133.36932477387&xp=585045.0300033365&tool=navigator&sid0=1&s0=7.400000000000001) you can browse the entire dataset. Zooming in and out is a lot of fun, don't get lost.\n",
    "\n",
    "The particular cutout you are looking at here, is itself a small cutout of the [CREMI](https://cremi.org/) challenge volumes: a neuron and synapse segmentation challenge that provides manually acquired ground truth and provides a way to quantitatively compare competing algorithmic approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroglancer\n",
    "import funlib.show.neuroglancer as funlibng\n",
    "import daisy\n",
    "import numpy as np\n",
    "\n",
    "# !!! IMPORTANT: Replace my_ip with your public paperspace ip as shown in your browser !!!\n",
    "\n",
    "def view_snapshot(pipeline_name, my_ip=\"74.82.31.73\", snapshot_file=\"./snapshots/snapshot\"):\n",
    "    neuroglancer.set_server_bind_address('0.0.0.0', 8889)\n",
    "    snapshot_file = snapshot_file + \"_\" + pipeline_name + \".hdf\"\n",
    "    \n",
    "    affs_ds = daisy.open_ds(snapshot_file, 'volumes/affinities')\n",
    "    affs_ds.data = np.array(affs_ds.data, dtype=np.float32)\n",
    "    labels_ds = daisy.open_ds(snapshot_file, 'volumes/labels/neuron_ids')\n",
    "    raw_ds = daisy.open_ds(snapshot_file, 'volumes/raw')\n",
    "\n",
    "    neuroglancer.set_server_bind_address('0.0.0.0')\n",
    "    viewer = neuroglancer.Viewer()\n",
    "    with viewer.txn() as s:\n",
    "        funlibng.add_layer(s, raw_ds, 'raw')\n",
    "        funlibng.add_layer(s, labels_ds, 'labels')\n",
    "        funlibng.add_layer(s, affs_ds, 'affinities', shader='rgb')\n",
    "\n",
    "    print(viewer.__str__().replace(\"localhost\", my_ip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://74.82.31.73:45325/v/3a164a418d62a25c1ae8b08b907b46d71fa4f30b/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/asyncio/events.py\", line 126, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/site-packages/tornado/iostream.py\", line 713, in _handle_events\n",
      "    self._handle_write()\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/site-packages/tornado/iostream.py\", line 1063, in _handle_write\n",
      "    self._write_buffer.advance(num_bytes)\n",
      "  File \"/home/paperspace/anaconda3/envs/segmentation/lib/python3.6/site-packages/tornado/iostream.py\", line 184, in advance\n",
      "    assert 0 < size <= self._size\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "view_snapshot(pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0.3\n",
    "## Extend the data manipulation pipeline from before by adding data augmentations. \n",
    "\n",
    "Observe how different augmentations and parameters thereof change the output by visualizing your data with neuroglancer.\n",
    "\n",
    "An example of how to use augmentation is given below. Play around with augmentation parameters and add more augmentation types. For more information about what type of augmentations are available in gunpowder see: http://funkey.science/gunpowder/api.html#augmentation-nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from gunpowder import *\n",
    "from gunpowder.tensorflow import *\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "# A simple gunpowder pipeline for loading and manipulating data:\n",
    "data_dir = '../../jan/segmentation/data'\n",
    "\n",
    "samples = [\n",
    "    'sample_A',\n",
    "    'sample_B',\n",
    "    'sample_C'\n",
    "]\n",
    "\n",
    "\n",
    "# Define gunpowder variables of interest:\n",
    "raw = ArrayKey('RAW') # Raw EM data\n",
    "labels = ArrayKey('GT_LABELS') # ground truth neuron segmentation \n",
    "affinities = ArrayKey('GT_AFFINITIES') # affinities\n",
    "\n",
    "# Voxel size is the physical size of one voxel (=3D pixel) in nm.\n",
    "voxel_size = Coordinate((40, 4, 4))\n",
    "batch_size = Coordinate((30,1000,1000)) * voxel_size\n",
    "\n",
    "# Request all the data you need for training:\n",
    "request = BatchRequest()\n",
    "request.add(raw, batch_size)\n",
    "request.add(labels, batch_size)\n",
    "request.add(affinities, batch_size)\n",
    "\n",
    "# Request a snapshot s.t. you are able to visualize the data in your pipeline.\n",
    "snapshot_request = BatchRequest({\n",
    "    raw: request[raw],\n",
    "    labels: request[labels],\n",
    "    affinities: request[affinities]\n",
    "})\n",
    "\n",
    "# Note that the data only provides raw and neuron_ids which is the neuron segmentation.\n",
    "# However, we need affinities which we can generate from neuron_ids by using gunpowder (see below):\n",
    "data_sources = tuple(\n",
    "    N5Source(\n",
    "        os.path.join(data_dir, sample + '.n5'),\n",
    "        datasets = {\n",
    "            raw: 'volumes/raw',\n",
    "            labels: 'volumes/labels/neuron_ids',\n",
    "        },\n",
    "        array_specs = {\n",
    "            raw: ArraySpec(interpolatable=True),\n",
    "            labels: ArraySpec(interpolatable=False)\n",
    "        }\n",
    "    ) +\n",
    "    Normalize(raw) + \n",
    "    RandomLocation()\n",
    "    for sample in samples\n",
    "    )\n",
    "\n",
    "\n",
    "# Define a neighborhood for affinities:\n",
    "neighborhood = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]\n",
    "\n",
    "pipeline = (\n",
    "    data_sources +\n",
    "    RandomProvider() +\n",
    "    ElasticAugment(\n",
    "            control_point_spacing=[4,40,40],\n",
    "            jitter_sigma=[0,2,2],\n",
    "            rotation_interval=[0,math.pi/2.0],\n",
    "            prob_slip=0.05,\n",
    "            prob_shift=0.05,\n",
    "            max_misalign=10,\n",
    "            subsample=8) +\n",
    "    SimpleAugment(transpose_only=[1, 2]) +\n",
    "    IntensityAugment(raw, 0.9, 1.1, -0.1, 0.1, z_section_wise=True) +\n",
    "    AddAffinities(neighborhood,\n",
    "                 labels=labels,\n",
    "                 affinities=affinities) +\n",
    "    Snapshot({raw: 'volumes/raw',\n",
    "              labels: 'volumes/labels/neuron_ids',\n",
    "              affinities: 'volumes/affinities'}))\n",
    "    \n",
    "    \n",
    "with build(pipeline) as b:\n",
    "    b.request_batch(request)\n",
    "    \n",
    "view_snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## Using gunpowder with tensorflow for training a 3D-UNet for affinity prediction\n",
    "#### mknet.py\n",
    "\n",
    "In this exercise we ask you to fill in the given template file to create a computation graph for your neural network. Follow the instructions in the code and make use of help and documentations.\n",
    "\n",
    "As usual if you are not sure about what a function does or what its argument is navigate to the function and press ```shift + tab``` to display arguments and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating U-Net layer 0\n",
      "f_in: (1, 1, 84, 268, 268)\n",
      "number of variables added: 4236, new total: 4236\n",
      "    Creating U-Net layer 1\n",
      "    f_in: (1, 12, 80, 88, 88)\n",
      "    number of variables added: 116760, new total: 120996\n",
      "        Creating U-Net layer 2\n",
      "        f_in: (1, 60, 76, 28, 28)\n",
      "        number of variables added: 2916600, new total: 3037596\n",
      "            Creating U-Net layer 3\n",
      "            f_in: (1, 300, 24, 8, 8)\n",
      "            bottom layer\n",
      "            f_out: (1, 1500, 20, 4, 4)\n",
      "            number of variables added: 72903000, new total: 75940596\n",
      "        g_out: (1, 1500, 20, 4, 4)\n",
      "        g_out_upsampled: (1, 300, 60, 12, 12)\n",
      "        f_left_cropped: (1, 300, 60, 12, 12)\n",
      "        f_right: (1, 600, 60, 12, 12)\n",
      "        f_out: (1, 300, 56, 8, 8)\n",
      "        number of variables added: 19440900, new total: 95381496\n",
      "    g_out: (1, 300, 56, 8, 8)\n",
      "    g_out_upsampled: (1, 60, 56, 24, 24)\n",
      "    f_left_cropped: (1, 60, 56, 24, 24)\n",
      "    f_right: (1, 120, 56, 24, 24)\n",
      "    f_out: (1, 60, 52, 20, 20)\n",
      "    number of variables added: 453780, new total: 95835276\n",
      "g_out: (1, 60, 52, 20, 20)\n",
      "g_out_upsampled: (1, 12, 52, 60, 60)\n",
      "f_left_cropped: (1, 12, 52, 60, 60)\n",
      "f_right: (1, 24, 52, 60, 60)\n",
      "f_out: (1, 12, 48, 56, 56)\n",
      "number of variables added: 18180, new total: 95853456\n",
      "WARNING:tensorflow:From /groups/funke/home/ecksteinn/miniconda2/envs/segmentation/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "input shape : (84, 268, 268)\n",
      "output shape: [48, 56, 56]\n",
      "Creating U-Net layer 0\n",
      "f_in: (1, 1, 114, 646, 646)\n",
      "number of variables added: 4236, new total: 4236\n",
      "    Creating U-Net layer 1\n",
      "    f_in: (1, 12, 110, 214, 214)\n",
      "    number of variables added: 116760, new total: 120996\n",
      "        Creating U-Net layer 2\n",
      "        f_in: (1, 60, 106, 70, 70)\n",
      "        number of variables added: 2916600, new total: 3037596\n",
      "            Creating U-Net layer 3\n",
      "            f_in: (1, 300, 34, 22, 22)\n",
      "            bottom layer\n",
      "            f_out: (1, 1500, 30, 18, 18)\n",
      "            number of variables added: 72903000, new total: 75940596\n",
      "        g_out: (1, 1500, 30, 18, 18)\n",
      "        g_out_upsampled: (1, 300, 90, 54, 54)\n",
      "        f_left_cropped: (1, 300, 90, 54, 54)\n",
      "        f_right: (1, 600, 90, 54, 54)\n",
      "        f_out: (1, 300, 86, 50, 50)\n",
      "        number of variables added: 19440900, new total: 95381496\n",
      "    g_out: (1, 300, 86, 50, 50)\n",
      "    g_out_upsampled: (1, 60, 86, 150, 150)\n",
      "    f_left_cropped: (1, 60, 86, 150, 150)\n",
      "    f_right: (1, 120, 86, 150, 150)\n",
      "    f_out: (1, 60, 82, 146, 146)\n",
      "    number of variables added: 453780, new total: 95835276\n",
      "g_out: (1, 60, 82, 146, 146)\n",
      "g_out_upsampled: (1, 12, 82, 438, 438)\n",
      "f_left_cropped: (1, 12, 82, 438, 438)\n",
      "f_right: (1, 24, 82, 438, 438)\n",
      "f_out: (1, 12, 78, 434, 434)\n",
      "number of variables added: 18180, new total: 95853456\n",
      "input shape : (114, 646, 646)\n",
      "output shape: [78, 434, 434]\n"
     ]
    }
   ],
   "source": [
    "from funlib.learn.tensorflow import models\n",
    "import malis\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "def create_network(input_shape, name):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.variable_scope('setup0'):\n",
    "\n",
    "        raw = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        raw_batched = tf.reshape(raw, (1, 1) + input_shape)\n",
    "\n",
    "        unet, _, _ = models.unet(\n",
    "                raw_batched,\n",
    "                12,\n",
    "                5,\n",
    "                [[1,3,3],[1,3,3],[3,3,3]])\n",
    "\n",
    "        affs_batched, _ = models.conv_pass(\n",
    "            unet,\n",
    "            kernel_sizes=[1],\n",
    "            num_fmaps=3,\n",
    "            activation='sigmoid',\n",
    "            name='affs')\n",
    "\n",
    "        output_shape_batched = affs_batched.get_shape().as_list()\n",
    "        output_shape = output_shape_batched[1:] # strip the batch dimension\n",
    "\n",
    "        affs = tf.reshape(affs_batched, output_shape)\n",
    "\n",
    "        gt_affs = tf.placeholder(tf.float32, shape=output_shape)\n",
    "        affs_loss_weights = tf.placeholder(tf.float32, shape=output_shape)\n",
    "\n",
    "        loss = tf.losses.mean_squared_error(\n",
    "            gt_affs,\n",
    "            affs,\n",
    "            affs_loss_weights)\n",
    "\n",
    "        summary = tf.summary.scalar('setup0', loss)\n",
    "\n",
    "        opt = tf.train.AdamOptimizer(\n",
    "            learning_rate=0.5e-4,\n",
    "            beta1=0.95,\n",
    "            beta2=0.999,\n",
    "            epsilon=1e-8)\n",
    "        optimizer = opt.minimize(loss)\n",
    "\n",
    "        output_shape = output_shape[1:]\n",
    "        print(\"input shape : %s\"%(input_shape,))\n",
    "        print(\"output shape: %s\"%(output_shape,))\n",
    "\n",
    "        tf.train.export_meta_graph(filename=name + '.meta')\n",
    "\n",
    "        config = {\n",
    "            'raw': raw.name,\n",
    "            'affs': affs.name,\n",
    "            'gt_affs': gt_affs.name,\n",
    "            'affs_loss_weights': affs_loss_weights.name,\n",
    "            'loss': loss.name,\n",
    "            'optimizer': optimizer.name,\n",
    "            'input_shape': input_shape,\n",
    "            'output_shape': output_shape,\n",
    "            'summary': summary.name\n",
    "        }\n",
    "\n",
    "        config['outputs'] = {'affs': {\"out_dims\": 3, \"out_dtype\": \"uint8\"}}\n",
    "\n",
    "        with open(name + '.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_network((84, 268, 268), 'train_net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "## A gunpowder training pipeline\n",
    "\n",
    "In this exercise we ask you to use gunpowder in combination with tensorflow to build a training pipeline for affinity prediction. Fill in the gaps in the template code below and train your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gunpowder.tensorflow.local_server:Creating local tensorflow server\n",
      "INFO:gunpowder.tensorflow.local_server:Server running at b'grpc://localhost:36769'\n",
      "INFO:gunpowder.tensorflow.nodes.train:Initializing tf session, connecting to b'grpc://localhost:36769'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT:  (960, 112, 112)\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gunpowder.tensorflow.nodes.train:Reading meta-graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /groups/funke/home/ecksteinn/miniconda2/envs/segmentation/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /groups/funke/home/ecksteinn/miniconda2/envs/segmentation/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:gunpowder.tensorflow.nodes.train:No checkpoint found\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#import multiprocessing\n",
    "#multiprocessing.set_start_method('forkserver')\n",
    "import sys\n",
    "from gunpowder import *\n",
    "from gunpowder.tensorflow import *\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "data_dir = '../../jan/segmentation/data'\n",
    "\n",
    "samples = [\n",
    "    'sample_A',\n",
    "    'sample_B',\n",
    "    'sample_C'\n",
    "]\n",
    "\n",
    "neighborhood = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]\n",
    "\n",
    "def train_until(max_iteration):\n",
    "\n",
    "    if tf.train.latest_checkpoint('.'):\n",
    "        trained_until = int(tf.train.latest_checkpoint('.').split('_')[-1])\n",
    "    else:\n",
    "        trained_until = 0\n",
    "    if trained_until >= max_iteration:\n",
    "        return\n",
    "\n",
    "    with open('train_net.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    raw = ArrayKey('RAW')\n",
    "    labels = ArrayKey('GT_LABELS')\n",
    "    labels_mask = ArrayKey('GT_LABELS_MASK')\n",
    "    affs = ArrayKey('PREDICTED_AFFS')\n",
    "    gt = ArrayKey('GT_AFFINITIES')\n",
    "    gt_mask = ArrayKey('GT_AFFINITIES_MASK')\n",
    "    gt_scale = ArrayKey('GT_AFFINITIES_SCALE')\n",
    "    affs_gradient = ArrayKey('AFFS_GRADIENT')\n",
    "\n",
    "    voxel_size = Coordinate((40, 4, 4))\n",
    "    input_size = Coordinate(config['input_shape'])*voxel_size\n",
    "    output_size = Coordinate(config['output_shape'])*voxel_size\n",
    "    context = output_size/2\n",
    "    print('CONTEXT: ', context)\n",
    "\n",
    "    request = BatchRequest()\n",
    "    request.add(raw, input_size)\n",
    "    request.add(labels, output_size)\n",
    "    request.add(labels_mask, output_size)\n",
    "    request.add(gt, output_size)\n",
    "    request.add(gt_mask, output_size)\n",
    "    request.add(gt_scale, output_size)\n",
    "\n",
    "    snapshot_request = BatchRequest({\n",
    "        affs: request[gt],\n",
    "        affs_gradient: request[gt]\n",
    "    })\n",
    "\n",
    "    data_sources = tuple(\n",
    "        N5Source(\n",
    "            os.path.join(data_dir, sample + '.n5'),\n",
    "            datasets = {\n",
    "                raw: 'volumes/raw',\n",
    "                labels: 'volumes/labels/neuron_ids',\n",
    "                labels_mask: 'volumes/labels/mask',\n",
    "            },\n",
    "            array_specs = {\n",
    "                raw: ArraySpec(interpolatable=True),\n",
    "                labels: ArraySpec(interpolatable=False),\n",
    "                labels_mask: ArraySpec(interpolatable=False)\n",
    "            }\n",
    "        ) +\n",
    "        Normalize(raw) +\n",
    "        Pad(labels, context) +\n",
    "        Pad(labels_mask, context) +\n",
    "        RandomLocation() +\n",
    "        Reject(mask=labels_mask)\n",
    "        for sample in samples\n",
    "    )\n",
    "\n",
    "\n",
    "    train_pipeline = (\n",
    "        data_sources +\n",
    "        RandomProvider() +\n",
    "        ElasticAugment(\n",
    "            control_point_spacing=[4,40,40],\n",
    "            jitter_sigma=[0,2,2],\n",
    "            rotation_interval=[0,math.pi/2.0],\n",
    "            prob_slip=0.05,\n",
    "            prob_shift=0.05,\n",
    "            max_misalign=10,\n",
    "            subsample=8) +\n",
    "        SimpleAugment(transpose_only=[1, 2]) +\n",
    "        IntensityAugment(raw, 0.9, 1.1, -0.1, 0.1, z_section_wise=True) +\n",
    "        GrowBoundary(labels, labels_mask, steps=1, only_xy=True) +\n",
    "        AddAffinities(\n",
    "            neighborhood,\n",
    "            labels=labels,\n",
    "            affinities=gt,\n",
    "            labels_mask=labels_mask,\n",
    "            affinities_mask=gt_mask) +\n",
    "        BalanceLabels(\n",
    "            gt,\n",
    "            gt_scale,\n",
    "            gt_mask) +\n",
    "        DefectAugment(\n",
    "            raw,\n",
    "            prob_missing=0.03,\n",
    "            prob_low_contrast=0.01,\n",
    "            contrast_scale=0.5,\n",
    "            axis=0) +\n",
    "        IntensityScaleShift(raw, 2,-1) +\n",
    "        PreCache(cache_size=40,\n",
    "                 num_workers=10) +\n",
    "        Train(\n",
    "            'train_net',\n",
    "            optimizer=config['optimizer'],\n",
    "            loss=config['loss'],\n",
    "            inputs={\n",
    "                config['raw']: raw,\n",
    "                config['gt_affs']: gt,\n",
    "                config['affs_loss_weights']: gt_scale,\n",
    "            },\n",
    "            outputs={\n",
    "                config['affs']: affs\n",
    "            },\n",
    "            gradients={\n",
    "                config['affs']: affs_gradient\n",
    "            },\n",
    "            summary=config['summary'],\n",
    "            log_dir='log',\n",
    "            save_every=10000) +\n",
    "        IntensityScaleShift(raw, 0.5, 0.5) +\n",
    "        Snapshot({\n",
    "                raw: 'volumes/raw',\n",
    "                labels: 'volumes/labels/neuron_ids',\n",
    "                gt: 'volumes/gt_affinities',\n",
    "                affs: 'volumes/pred_affinities',\n",
    "                gt_mask: 'volumes/labels/gt_mask',\n",
    "                labels_mask: 'volumes/labels/mask',\n",
    "                affs_gradient: 'volumes/affs_gradient'\n",
    "            },\n",
    "            dataset_dtypes={\n",
    "                labels: np.uint64\n",
    "            },\n",
    "            every=1000,\n",
    "            output_filename='batch_{iteration}.hdf',\n",
    "            additional_request=snapshot_request) +\n",
    "        PrintProfilingStats(every=10)\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    with build(train_pipeline) as b:\n",
    "        for i in range(max_iteration - trained_until):\n",
    "            b.request_batch(request)\n",
    "    print(\"Training finished\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    iteration = 500000\n",
    "    train_until(iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "## Monitor the training progress\n",
    "\n",
    "Visualize the generated training snapshots with neuroglancer and observe loss curves using tensorboard.\n",
    "\n",
    "\n",
    "#### Snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroglancer\n",
    "import funlib.show.neuroglancer as funlibng\n",
    "import daisy\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "data_file = ...\n",
    "\"\"\"\n",
    "\n",
    "gt_affs_ds = daisy.open_ds(data_file, 'volumes/gt_affinities')\n",
    "gt_affs_ds.data = np.array(gt_affs_ds.data, dtype=np.float32)\n",
    "\n",
    "pred_affs_ds = daisy.open_ds(data_file, 'volumes/pred_affinities')\n",
    "pred_affs_ds.data = np.array(pred_affs_ds.data, dtype=np.float32)\n",
    "\n",
    "gradients_ds = daisy.open_ds(data_file, 'volumes/affs_gradient')\n",
    "\n",
    "labels_ds = daisy.open_ds(data_file, 'volumes/labels/neuron_ids')\n",
    "raw_ds = daisy.open_ds(data_file, 'volumes/raw')\n",
    "\n",
    "# Replace my_ip with your public paperspace ip as shown in your browser\n",
    "my_ip = \"172.83.14.204\"\n",
    "neuroglancer.set_server_bind_address('0.0.0.0', 8889)\n",
    "\n",
    "viewer = neuroglancer.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    funlibng.add_layer(s, raw_ds, 'raw')\n",
    "    funlibng.add_layer(s, labels_ds, 'labels')\n",
    "    funlibng.add_layer(s, gt_affs_ds, 'gt_affinities', shader='rgb')\n",
    "    funlibng.add_layer(s, pred_affs_ds, 'pred_affinities', shader='rgb')\n",
    "    funlibng.add_layer(s, gradients_ds, 'gradients')\n",
    "\n",
    "print(viewer.__str__().replace(\"localhost\", my_ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss\n",
    "To visualize your loss using tensorboard open a terminal and execute: \n",
    "```tensorboard --logdir=path/to/log-directory```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:segmentation]",
   "language": "python",
   "name": "conda-env-segmentation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
